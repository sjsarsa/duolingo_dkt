{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This has been slightly modified for duolingo competition\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score, accuracy_score, log_loss\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "# flags\n",
    "# tf.flags.DEFINE_float(\"epsilon\", 0.1, \"Epsilon value for Adam Optimizer.\")\n",
    "# tf.flags.DEFINE_float(\"l2_lambda\", 0.3, \"Lambda for l2 loss.\")\n",
    "# tf.flags.DEFINE_float(\"learning_rate\", 0.1, \"Learning rate\")\n",
    "# tf.flags.DEFINE_float(\"max_grad_norm\", 20.0, \"Clip gradients to this norm.\")\n",
    "# tf.flags.DEFINE_float(\"keep_prob\", 0.6, \"Keep probability for dropout\")\n",
    "# tf.flags.DEFINE_integer(\"hidden_layer_num\", 1, \"The number of hidden layers (Integer)\")\n",
    "# tf.flags.DEFINE_integer(\"hidden_size\", 200, \"The number of hidden nodes (Integer)\")\n",
    "# tf.flags.DEFINE_integer(\"evaluation_interval\", 5, \"Evaluate and print results every x epochs\")\n",
    "# tf.flags.DEFINE_integer(\"batch_size\", 32, \"Batch size for training.\")\n",
    "# tf.flags.DEFINE_integer(\"epochs\", 150, \"Number of epochs to train for.\")\n",
    "# tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "# tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "# tf.flags.DEFINE_boolean(\"save_test_logits\", False, \"Save test data logits on disk\")\n",
    "# tf.flags.DEFINE_string(\"train_data_path\", 'data_fr_en/formatted_data_train.csv', \"Path to the training dataset\")\n",
    "# tf.flags.DEFINE_string(\"test_data_path\", 'data_fr_en/formatted_data_test.csv', \"Path to the testing dataset\")\n",
    "\n",
    "\n",
    "# FLAGS = tf.flags.FLAGS\n",
    "# FLAGS(sys.argv, known_only=True)\n",
    "# remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\n",
    "# assert(remaining_args == [sys.argv[0]])\n",
    "#FLAGS._parse_flags()\n",
    "class FLAGS:\n",
    "    kind = 'canine'\n",
    "    epsilon = 0.1\n",
    "    l2_lambda= 0.3\n",
    "    learning_rate = 0.003\n",
    "    max_grad_norm = 20.0\n",
    "    keep_prob = 0.6\n",
    "    hidden_layer_num = 1\n",
    "    hidden_size = 150\n",
    "    evaluation_interval = 5\n",
    "    batch_size = 10\n",
    "    epochs = 300\n",
    "    allow_soft_placement = True\n",
    "    log_device_placement = False\n",
    "    save_test_logits = False\n",
    "    train_data_path = 'data_fr_en/formatted_data_train_w.csv'\n",
    "    test_data_path = 'data_fr_en/formatted_data_test_w.csv'\n",
    "\n",
    "# for attr, value in sorted(FLAGS.__flags.items()):\n",
    "#     print(\"{}={}\".format(attr.upper(), value))\n",
    "# print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of rows is 5010\n",
      "The number of students is  1670\n",
      "Finish reading data\n",
      "train_max_num_problems=808, train_max_skill_num=3450\n",
      "the number of rows is 3615\n",
      "The number of students is  1205\n",
      "Finish reading data\n",
      "test_max_num_problems=1286, test_max_skill_num=3653\n",
      "Reading time 0.4 s\n",
      "Time checkpoint 0.4076 s\n",
      "Starting tf session...\n",
      "Time checkpoint 1.0548 min\n",
      "Running session...\n",
      "Writing hyperparameters into file\n",
      "Starting epochs...\n",
      "Time checkpoint 1.1229 min\n",
      "Running epoch 1...\n",
      "Total epoch time: 100.69543313980103d in 0.4304s, epoch ETA: 0.4304s\t\n",
      "Epoch: 1 Train Metrics:\n",
      " acc: 0.807 log loss: 0.453 \t f1: 0.275 \t rmse: 0.383 \t auc: 0.683 \t r2: -0.081 \n",
      "\n",
      "Running epoch 2...\n",
      "Total epoch time: 75.61328649520874ed in 0.4416s, epoch ETA: 0.4416s\t\n",
      "Epoch: 2 Train Metrics:\n",
      " acc: 0.848 log loss: 0.375 \t f1: 0.262 \t rmse: 0.341 \t auc: 0.766 \t r2: 0.147 \n",
      "\n",
      "Running epoch 3...\n",
      "Total epoch time: 75.56995892524719ed in 0.446s, epoch ETA: 0.4461s\t\t\n",
      "Epoch: 3 Train Metrics:\n",
      " acc: 0.850 log loss: 0.372 \t f1: 0.262 \t rmse: 0.339 \t auc: 0.771 \t r2: 0.156 \n",
      "\n",
      "Running epoch 4...\n",
      "Total epoch time: 75.4765350818634ted in 0.4311s, epoch ETA: 0.4311s\t\n",
      "Epoch: 4 Train Metrics:\n",
      " acc: 0.850 log loss: 0.370 \t f1: 0.262 \t rmse: 0.338 \t auc: 0.773 \t r2: 0.160 \n",
      "\n",
      "Running epoch 5...\n",
      "Total epoch time: 75.37050986289978ed in 0.4437s, epoch ETA: 0.4437s\t\n",
      "Epoch: 5 Train Metrics:\n",
      " acc: 0.850 log loss: 0.369 \t f1: 0.262 \t rmse: 0.337 \t auc: 0.776 \t r2: 0.164 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.899738073349eted in 0.357s, epoch ETA: 0.1785s\t\t\n",
      "Epoch: 5 Test Metrics:\n",
      " acc: 0.831 \t log loss: 0.406 \t f1: 0.240 \t rmse: 0.357 \t auc: 0.747 \t r2: 0.123\n",
      "**********\n",
      "Running epoch 6...\n",
      "Total epoch time: 75.38928818702698ed in 0.4453s, epoch ETA: 0.4453s\t\n",
      "Epoch: 6 Train Metrics:\n",
      " acc: 0.851 log loss: 0.367 \t f1: 0.262 \t rmse: 0.337 \t auc: 0.779 \t r2: 0.167 \n",
      "\n",
      "Running epoch 7...\n",
      "Total epoch time: 75.54753041267395ed in 0.4422s, epoch ETA: 0.4422s\t\n",
      "Epoch: 7 Train Metrics:\n",
      " acc: 0.851 log loss: 0.366 \t f1: 0.263 \t rmse: 0.336 \t auc: 0.781 \t r2: 0.171 \n",
      "\n",
      "Running epoch 8...\n",
      "Total epoch time: 75.52781987190247ed in 0.4477s, epoch ETA: 0.4477s\t\n",
      "Epoch: 8 Train Metrics:\n",
      " acc: 0.852 log loss: 0.364 \t f1: 0.267 \t rmse: 0.335 \t auc: 0.784 \t r2: 0.174 \n",
      "\n",
      "Running epoch 9...\n",
      "Total epoch time: 75.69145560264587ed in 0.4501s, epoch ETA: 0.4501s\t\n",
      "Epoch: 9 Train Metrics:\n",
      " acc: 0.852 log loss: 0.362 \t f1: 0.270 \t rmse: 0.334 \t auc: 0.787 \t r2: 0.178 \n",
      "\n",
      "Running epoch 10...\n",
      "Total epoch time: 75.5866105556488ted in 0.4322s, epoch ETA: 0.4322s\t\n",
      "Epoch: 10 Train Metrics:\n",
      " acc: 0.853 log loss: 0.361 \t f1: 0.275 \t rmse: 0.333 \t auc: 0.789 \t r2: 0.182 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.47233510017395ed in 0.3448s, epoch ETA: 0.1724s\t\n",
      "Epoch: 10 Test Metrics:\n",
      " acc: 0.833 \t log loss: 0.397 \t f1: 0.243 \t rmse: 0.353 \t auc: 0.761 \t r2: 0.144\n",
      "**********\n",
      "Running epoch 11...\n",
      "Total epoch time: 75.63959980010986ed in 0.4436s, epoch ETA: 0.4436s\t\n",
      "Epoch: 11 Train Metrics:\n",
      " acc: 0.853 log loss: 0.359 \t f1: 0.281 \t rmse: 0.333 \t auc: 0.791 \t r2: 0.187 \n",
      "\n",
      "Running epoch 12...\n",
      "Total epoch time: 75.6747739315033ted in 0.4447s, epoch ETA: 0.4447s\t\n",
      "Epoch: 12 Train Metrics:\n",
      " acc: 0.854 log loss: 0.358 \t f1: 0.288 \t rmse: 0.332 \t auc: 0.793 \t r2: 0.190 \n",
      "\n",
      "Running epoch 13...\n",
      "Total epoch time: 75.37046241760254ed in 0.4408s, epoch ETA: 0.4408s\t\n",
      "Epoch: 13 Train Metrics:\n",
      " acc: 0.855 log loss: 0.356 \t f1: 0.293 \t rmse: 0.331 \t auc: 0.796 \t r2: 0.194 \n",
      "\n",
      "Running epoch 14...\n",
      "Total epoch time: 75.46768832206726ed in 0.4412s, epoch ETA: 0.4412s\t\n",
      "Epoch: 14 Train Metrics:\n",
      " acc: 0.855 log loss: 0.354 \t f1: 0.299 \t rmse: 0.330 \t auc: 0.798 \t r2: 0.199 \n",
      "\n",
      "Running epoch 15...\n",
      "Total epoch time: 75.65127396583557ed in 0.443s, epoch ETA: 0.443s\t\t\n",
      "Epoch: 15 Train Metrics:\n",
      " acc: 0.856 log loss: 0.351 \t f1: 0.306 \t rmse: 0.329 \t auc: 0.802 \t r2: 0.205 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.7751259803772ted in 0.3444s, epoch ETA: 0.1722s\t\n",
      "Epoch: 15 Test Metrics:\n",
      " acc: 0.837 \t log loss: 0.389 \t f1: 0.264 \t rmse: 0.348 \t auc: 0.774 \t r2: 0.165\n",
      "**********\n",
      "Running epoch 16...\n",
      "Total epoch time: 75.45720672607422ed in 0.4422s, epoch ETA: 0.4422s\t\n",
      "Epoch: 16 Train Metrics:\n",
      " acc: 0.857 log loss: 0.350 \t f1: 0.314 \t rmse: 0.328 \t auc: 0.804 \t r2: 0.209 \n",
      "\n",
      "Running epoch 17...\n",
      "Total epoch time: 75.394686460495eted in 0.4415s, epoch ETA: 0.4415s\t\n",
      "Epoch: 17 Train Metrics:\n",
      " acc: 0.857 log loss: 0.349 \t f1: 0.318 \t rmse: 0.327 \t auc: 0.806 \t r2: 0.212 \n",
      "\n",
      "Running epoch 18...\n",
      "Total epoch time: 75.79006958007812ed in 0.4422s, epoch ETA: 0.4422s\t\n",
      "Epoch: 18 Train Metrics:\n",
      " acc: 0.858 log loss: 0.347 \t f1: 0.327 \t rmse: 0.326 \t auc: 0.808 \t r2: 0.217 \n",
      "\n",
      "Running epoch 19...\n",
      "Total epoch time: 75.51022672653198ed in 0.4416s, epoch ETA: 0.4416s\t\n",
      "Epoch: 19 Train Metrics:\n",
      " acc: 0.858 log loss: 0.346 \t f1: 0.331 \t rmse: 0.326 \t auc: 0.810 \t r2: 0.219 \n",
      "\n",
      "Running epoch 20...\n",
      "Total epoch time: 75.30373692512512ed in 0.4134s, epoch ETA: 0.4134s\t\n",
      "Epoch: 20 Train Metrics:\n",
      " acc: 0.858 log loss: 0.345 \t f1: 0.335 \t rmse: 0.325 \t auc: 0.811 \t r2: 0.221 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.60775351524353ed in 0.3447s, epoch ETA: 0.1724s\t\n",
      "Epoch: 20 Test Metrics:\n",
      " acc: 0.841 \t log loss: 0.382 \t f1: 0.318 \t rmse: 0.345 \t auc: 0.784 \t r2: 0.182\n",
      "**********\n",
      "Running epoch 21...\n",
      "Total epoch time: 75.31932950019836ed in 0.4416s, epoch ETA: 0.4416s\t\n",
      "Epoch: 21 Train Metrics:\n",
      " acc: 0.859 log loss: 0.344 \t f1: 0.338 \t rmse: 0.325 \t auc: 0.812 \t r2: 0.224 \n",
      "\n",
      "Running epoch 22...\n",
      "Total epoch time: 75.44437861442566ed in 0.443s, epoch ETA: 0.443s\ts\t\n",
      "Epoch: 22 Train Metrics:\n",
      " acc: 0.859 log loss: 0.344 \t f1: 0.342 \t rmse: 0.325 \t auc: 0.812 \t r2: 0.224 \n",
      "\n",
      "Running epoch 23...\n",
      "Total epoch time: 75.44387102127075ed in 0.4284s, epoch ETA: 0.4284s\t\n",
      "Epoch: 23 Train Metrics:\n",
      " acc: 0.860 log loss: 0.343 \t f1: 0.344 \t rmse: 0.324 \t auc: 0.814 \t r2: 0.228 \n",
      "\n",
      "Running epoch 24...\n",
      "Total epoch time: 75.6423351764679ted in 0.4486s, epoch ETA: 0.4486s\t\n",
      "Epoch: 24 Train Metrics:\n",
      " acc: 0.860 log loss: 0.341 \t f1: 0.351 \t rmse: 0.323 \t auc: 0.817 \t r2: 0.233 \n",
      "\n",
      "Running epoch 25...\n",
      "Total epoch time: 75.22547435760498ed in 0.4464s, epoch ETA: 0.4464s\t\n",
      "Epoch: 25 Train Metrics:\n",
      " acc: 0.861 log loss: 0.341 \t f1: 0.356 \t rmse: 0.323 \t auc: 0.816 \t r2: 0.231 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.31704878807068ed in 0.3475s, epoch ETA: 0.1738s\t\n",
      "Epoch: 25 Test Metrics:\n",
      " acc: 0.842 \t log loss: 0.378 \t f1: 0.321 \t rmse: 0.343 \t auc: 0.790 \t r2: 0.192\n",
      "**********\n",
      "Running epoch 26...\n",
      "Total epoch time: 75.33685612678528ed in 0.4485s, epoch ETA: 0.4485s\t\n",
      "Epoch: 26 Train Metrics:\n",
      " acc: 0.861 log loss: 0.340 \t f1: 0.360 \t rmse: 0.322 \t auc: 0.818 \t r2: 0.235 \n",
      "\n",
      "Running epoch 27...\n",
      "Total epoch time: 75.24113845825195ed in 0.441s, epoch ETA: 0.441s\ts\t\n",
      "Epoch: 27 Train Metrics:\n",
      " acc: 0.861 log loss: 0.339 \t f1: 0.364 \t rmse: 0.322 \t auc: 0.819 \t r2: 0.237 \n",
      "\n",
      "Running epoch 28...\n",
      "Total epoch time: 75.24373030662537ed in 0.4317s, epoch ETA: 0.4317s\t\n",
      "Epoch: 28 Train Metrics:\n",
      " acc: 0.861 log loss: 0.339 \t f1: 0.363 \t rmse: 0.322 \t auc: 0.819 \t r2: 0.237 \n",
      "\n",
      "Running epoch 29...\n",
      "Total epoch time: 75.39609265327454ed in 0.4413s, epoch ETA: 0.4413s\t\n",
      "Epoch: 29 Train Metrics:\n",
      " acc: 0.862 log loss: 0.338 \t f1: 0.366 \t rmse: 0.321 \t auc: 0.821 \t r2: 0.240 \n",
      "\n",
      "Running epoch 30...\n",
      "Total epoch time: 75.76433968544006ed in 0.442s, epoch ETA: 0.442s\ts\t\n",
      "Epoch: 30 Train Metrics:\n",
      " acc: 0.862 log loss: 0.337 \t f1: 0.370 \t rmse: 0.321 \t auc: 0.822 \t r2: 0.242 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.1440224647522ted in 0.3439s, epoch ETA: 0.1719s\t\n",
      "Epoch: 30 Test Metrics:\n",
      " acc: 0.843 \t log loss: 0.379 \t f1: 0.304 \t rmse: 0.343 \t auc: 0.790 \t r2: 0.192\n",
      "**********\n",
      "Running epoch 31...\n",
      "Total epoch time: 75.46755719184875ed in 0.4365s, epoch ETA: 0.4365s\t\n",
      "Epoch: 31 Train Metrics:\n",
      " acc: 0.862 log loss: 0.337 \t f1: 0.373 \t rmse: 0.321 \t auc: 0.822 \t r2: 0.243 \n",
      "\n",
      "Running epoch 32...\n",
      "Total epoch time: 75.15540409088135ed in 0.4364s, epoch ETA: 0.4364s\t\n",
      "Epoch: 32 Train Metrics:\n",
      " acc: 0.862 log loss: 0.337 \t f1: 0.372 \t rmse: 0.321 \t auc: 0.821 \t r2: 0.242 \n",
      "\n",
      "Running epoch 33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 75.34026551246643ed in 0.4314s, epoch ETA: 0.4314s\t\n",
      "Epoch: 33 Train Metrics:\n",
      " acc: 0.862 log loss: 0.336 \t f1: 0.375 \t rmse: 0.321 \t auc: 0.823 \t r2: 0.244 \n",
      "\n",
      "Running epoch 34...\n",
      "Total epoch time: 75.04298686981201ed in 0.4465s, epoch ETA: 0.4465s\t\n",
      "Epoch: 34 Train Metrics:\n",
      " acc: 0.863 log loss: 0.335 \t f1: 0.376 \t rmse: 0.320 \t auc: 0.824 \t r2: 0.246 \n",
      "\n",
      "Running epoch 35...\n",
      "Total epoch time: 75.08127212524414ed in 0.4162s, epoch ETA: 0.4162s\t\n",
      "Epoch: 35 Train Metrics:\n",
      " acc: 0.863 log loss: 0.335 \t f1: 0.379 \t rmse: 0.320 \t auc: 0.825 \t r2: 0.247 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.22095608711243ed in 0.3551s, epoch ETA: 0.1776s\t\n",
      "Epoch: 35 Test Metrics:\n",
      " acc: 0.845 \t log loss: 0.373 \t f1: 0.342 \t rmse: 0.340 \t auc: 0.795 \t r2: 0.204\n",
      "**********\n",
      "Running epoch 36...\n",
      "Total epoch time: 75.39515566825867ed in 0.4396s, epoch ETA: 0.4396s\t\n",
      "Epoch: 36 Train Metrics:\n",
      " acc: 0.863 log loss: 0.334 \t f1: 0.384 \t rmse: 0.320 \t auc: 0.825 \t r2: 0.249 \n",
      "\n",
      "Running epoch 37...\n",
      "Total epoch time: 75.05379509925842ed in 0.4375s, epoch ETA: 0.4375s\t\n",
      "Epoch: 37 Train Metrics:\n",
      " acc: 0.863 log loss: 0.335 \t f1: 0.382 \t rmse: 0.320 \t auc: 0.825 \t r2: 0.248 \n",
      "\n",
      "Running epoch 38...\n",
      "Total epoch time: 75.21370840072632ed in 0.4357s, epoch ETA: 0.4357s\t\n",
      "Epoch: 38 Train Metrics:\n",
      " acc: 0.863 log loss: 0.333 \t f1: 0.384 \t rmse: 0.319 \t auc: 0.827 \t r2: 0.252 \n",
      "\n",
      "Running epoch 39...\n",
      "Total epoch time: 75.24257159233093ed in 0.4133s, epoch ETA: 0.4133s\t\n",
      "Epoch: 39 Train Metrics:\n",
      " acc: 0.864 log loss: 0.333 \t f1: 0.389 \t rmse: 0.319 \t auc: 0.828 \t r2: 0.253 \n",
      "\n",
      "Running epoch 40...\n",
      "Total epoch time: 75.29167556762695ed in 0.4412s, epoch ETA: 0.4412s\t\n",
      "Epoch: 40 Train Metrics:\n",
      " acc: 0.864 log loss: 0.333 \t f1: 0.390 \t rmse: 0.319 \t auc: 0.827 \t r2: 0.252 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.03581500053406ed in 0.3569s, epoch ETA: 0.1785s\t\n",
      "Epoch: 40 Test Metrics:\n",
      " acc: 0.846 \t log loss: 0.372 \t f1: 0.355 \t rmse: 0.339 \t auc: 0.797 \t r2: 0.208\n",
      "**********\n",
      "Running epoch 41...\n",
      "Total epoch time: 75.03679919242859ed in 0.4346s, epoch ETA: 0.4346s\t\n",
      "Epoch: 41 Train Metrics:\n",
      " acc: 0.864 log loss: 0.332 \t f1: 0.388 \t rmse: 0.319 \t auc: 0.828 \t r2: 0.254 \n",
      "\n",
      "Running epoch 42...\n",
      "Total epoch time: 75.10776805877686ed in 0.4386s, epoch ETA: 0.4386s\t\n",
      "Epoch: 42 Train Metrics:\n",
      " acc: 0.864 log loss: 0.332 \t f1: 0.388 \t rmse: 0.319 \t auc: 0.828 \t r2: 0.254 \n",
      "\n",
      "Running epoch 43...\n",
      "Total epoch time: 75.12777614593506ed in 0.4358s, epoch ETA: 0.4358s\t\n",
      "Epoch: 43 Train Metrics:\n",
      " acc: 0.864 log loss: 0.332 \t f1: 0.392 \t rmse: 0.318 \t auc: 0.829 \t r2: 0.256 \n",
      "\n",
      "Running epoch 44...\n",
      "Total epoch time: 75.08565330505371ed in 0.4317s, epoch ETA: 0.4317s\t\n",
      "Epoch: 44 Train Metrics:\n",
      " acc: 0.864 log loss: 0.332 \t f1: 0.393 \t rmse: 0.318 \t auc: 0.828 \t r2: 0.255 \n",
      "\n",
      "Running epoch 45...\n",
      "Total epoch time: 75.48672246932983ed in 0.4339s, epoch ETA: 0.4339s\t\n",
      "Epoch: 45 Train Metrics:\n",
      " acc: 0.864 log loss: 0.331 \t f1: 0.394 \t rmse: 0.318 \t auc: 0.829 \t r2: 0.256 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.24661707878113ed in 0.3494s, epoch ETA: 0.1747s\t\n",
      "Epoch: 45 Test Metrics:\n",
      " acc: 0.846 \t log loss: 0.371 \t f1: 0.350 \t rmse: 0.339 \t auc: 0.799 \t r2: 0.210\n",
      "**********\n",
      "Running epoch 46...\n",
      "Total epoch time: 75.18020868301392ed in 0.4427s, epoch ETA: 0.4427s\t\n",
      "Epoch: 46 Train Metrics:\n",
      " acc: 0.865 log loss: 0.330 \t f1: 0.397 \t rmse: 0.318 \t auc: 0.830 \t r2: 0.258 \n",
      "\n",
      "Running epoch 47...\n",
      "Total epoch time: 75.2518572807312ted in 0.4428s, epoch ETA: 0.4428s\t\n",
      "Epoch: 47 Train Metrics:\n",
      " acc: 0.864 log loss: 0.332 \t f1: 0.390 \t rmse: 0.319 \t auc: 0.827 \t r2: 0.254 \n",
      "\n",
      "Running epoch 48...\n",
      "Total epoch time: 75.52754521369934ed in 0.4397s, epoch ETA: 0.4397s\t\n",
      "Epoch: 48 Train Metrics:\n",
      " acc: 0.865 log loss: 0.331 \t f1: 0.397 \t rmse: 0.318 \t auc: 0.830 \t r2: 0.258 \n",
      "\n",
      "Running epoch 49...\n",
      "Total epoch time: 75.521888256073eted in 0.4386s, epoch ETA: 0.4386s\t\n",
      "Epoch: 49 Train Metrics:\n",
      " acc: 0.865 log loss: 0.331 \t f1: 0.399 \t rmse: 0.318 \t auc: 0.830 \t r2: 0.258 \n",
      "\n",
      "Running epoch 50...\n",
      "Total epoch time: 75.31280851364136ed in 0.4352s, epoch ETA: 0.4352s\t\n",
      "Epoch: 50 Train Metrics:\n",
      " acc: 0.865 log loss: 0.330 \t f1: 0.400 \t rmse: 0.317 \t auc: 0.831 \t r2: 0.260 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.04223871231079ed in 0.3552s, epoch ETA: 0.1776s\t\n",
      "Epoch: 50 Test Metrics:\n",
      " acc: 0.847 \t log loss: 0.370 \t f1: 0.364 \t rmse: 0.338 \t auc: 0.800 \t r2: 0.213\n",
      "**********\n",
      "Running epoch 51...\n",
      "Total epoch time: 75.16088795661926ed in 0.435s, epoch ETA: 0.435s\ts\t\n",
      "Epoch: 51 Train Metrics:\n",
      " acc: 0.865 log loss: 0.329 \t f1: 0.401 \t rmse: 0.317 \t auc: 0.833 \t r2: 0.263 \n",
      "\n",
      "Running epoch 52...\n",
      "Total epoch time: 75.43464231491089ed in 0.4291s, epoch ETA: 0.4291s\t\n",
      "Epoch: 52 Train Metrics:\n",
      " acc: 0.866 log loss: 0.329 \t f1: 0.405 \t rmse: 0.317 \t auc: 0.832 \t r2: 0.263 \n",
      "\n",
      "Running epoch 53...\n",
      "Total epoch time: 75.53892612457275ed in 0.436s, epoch ETA: 0.436s\ts\t\n",
      "Epoch: 53 Train Metrics:\n",
      " acc: 0.865 log loss: 0.330 \t f1: 0.401 \t rmse: 0.317 \t auc: 0.831 \t r2: 0.260 \n",
      "\n",
      "Running epoch 54...\n",
      "Total epoch time: 75.14691591262817ed in 0.4247s, epoch ETA: 0.4247s\t\n",
      "Epoch: 54 Train Metrics:\n",
      " acc: 0.866 log loss: 0.329 \t f1: 0.404 \t rmse: 0.317 \t auc: 0.832 \t r2: 0.263 \n",
      "\n",
      "Running epoch 55...\n",
      "Total epoch time: 75.27345061302185ed in 0.4338s, epoch ETA: 0.4338s\t\n",
      "Epoch: 55 Train Metrics:\n",
      " acc: 0.866 log loss: 0.329 \t f1: 0.404 \t rmse: 0.317 \t auc: 0.832 \t r2: 0.263 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.11893272399902ed in 0.3444s, epoch ETA: 0.1722s\t\n",
      "Epoch: 55 Test Metrics:\n",
      " acc: 0.847 \t log loss: 0.369 \t f1: 0.365 \t rmse: 0.338 \t auc: 0.801 \t r2: 0.216\n",
      "**********\n",
      "Running epoch 56...\n",
      "Total epoch time: 75.24483370780945ed in 0.4429s, epoch ETA: 0.4429s\t\n",
      "Epoch: 56 Train Metrics:\n",
      " acc: 0.866 log loss: 0.327 \t f1: 0.407 \t rmse: 0.316 \t auc: 0.834 \t r2: 0.266 \n",
      "\n",
      "Running epoch 57...\n",
      "Total epoch time: 75.29570627212524ed in 0.4425s, epoch ETA: 0.4425s\t\n",
      "Epoch: 57 Train Metrics:\n",
      " acc: 0.866 log loss: 0.327 \t f1: 0.409 \t rmse: 0.316 \t auc: 0.834 \t r2: 0.267 \n",
      "\n",
      "Running epoch 58...\n",
      "Total epoch time: 75.1516969203949ted in 0.4399s, epoch ETA: 0.4399s\t\n",
      "Epoch: 58 Train Metrics:\n",
      " acc: 0.866 log loss: 0.327 \t f1: 0.408 \t rmse: 0.316 \t auc: 0.834 \t r2: 0.266 \n",
      "\n",
      "Running epoch 59...\n",
      "Total epoch time: 75.500324010849eted in 0.4395s, epoch ETA: 0.4395s\t\n",
      "Epoch: 59 Train Metrics:\n",
      " acc: 0.866 log loss: 0.326 \t f1: 0.412 \t rmse: 0.315 \t auc: 0.835 \t r2: 0.268 \n",
      "\n",
      "Running epoch 60...\n",
      "Total epoch time: 75.3042504787445ted in 0.4479s, epoch ETA: 0.4479s\t\n",
      "Epoch: 60 Train Metrics:\n",
      " acc: 0.867 log loss: 0.326 \t f1: 0.414 \t rmse: 0.315 \t auc: 0.836 \t r2: 0.269 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.97187161445618ed in 0.3495s, epoch ETA: 0.1748s\t\n",
      "Epoch: 60 Test Metrics:\n",
      " acc: 0.847 \t log loss: 0.371 \t f1: 0.346 \t rmse: 0.338 \t auc: 0.801 \t r2: 0.213\n",
      "**********\n",
      "Running epoch 61...\n",
      "Total epoch time: 75.36929106712341ed in 0.4414s, epoch ETA: 0.4414s\t\n",
      "Epoch: 61 Train Metrics:\n",
      " acc: 0.866 log loss: 0.328 \t f1: 0.408 \t rmse: 0.316 \t auc: 0.833 \t r2: 0.266 \n",
      "\n",
      "Running epoch 62...\n",
      "Total epoch time: 75.51010227203369ed in 0.4445s, epoch ETA: 0.4445s\t\n",
      "Epoch: 62 Train Metrics:\n",
      " acc: 0.867 log loss: 0.326 \t f1: 0.412 \t rmse: 0.315 \t auc: 0.836 \t r2: 0.269 \n",
      "\n",
      "Running epoch 63...\n",
      "Total epoch time: 75.20967125892639ed in 0.4235s, epoch ETA: 0.4235s\t\n",
      "Epoch: 63 Train Metrics:\n",
      " acc: 0.866 log loss: 0.327 \t f1: 0.412 \t rmse: 0.316 \t auc: 0.834 \t r2: 0.267 \n",
      "\n",
      "Running epoch 64...\n",
      "Total epoch time: 75.22114419937134ed in 0.4413s, epoch ETA: 0.4413s\t\n",
      "Epoch: 64 Train Metrics:\n",
      " acc: 0.867 log loss: 0.326 \t f1: 0.412 \t rmse: 0.315 \t auc: 0.835 \t r2: 0.268 \n",
      "\n",
      "Running epoch 65...\n",
      "Total epoch time: 75.27599811553955ed in 0.4372s, epoch ETA: 0.4372s\t\n",
      "Epoch: 65 Train Metrics:\n",
      " acc: 0.867 log loss: 0.326 \t f1: 0.413 \t rmse: 0.315 \t auc: 0.836 \t r2: 0.269 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.30213284492493ed in 0.3446s, epoch ETA: 0.1723s\t\n",
      "Epoch: 65 Test Metrics:\n",
      " acc: 0.848 \t log loss: 0.370 \t f1: 0.348 \t rmse: 0.338 \t auc: 0.802 \t r2: 0.216\n",
      "**********\n",
      "Running epoch 66...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 75.31276249885559ed in 0.4439s, epoch ETA: 0.444s\t\t\n",
      "Epoch: 66 Train Metrics:\n",
      " acc: 0.867 log loss: 0.325 \t f1: 0.417 \t rmse: 0.315 \t auc: 0.837 \t r2: 0.271 \n",
      "\n",
      "Running epoch 67...\n",
      "Total epoch time: 75.34398674964905ed in 0.4283s, epoch ETA: 0.4283s\t\n",
      "Epoch: 67 Train Metrics:\n",
      " acc: 0.867 log loss: 0.325 \t f1: 0.415 \t rmse: 0.315 \t auc: 0.836 \t r2: 0.270 \n",
      "\n",
      "Running epoch 68...\n",
      "Total epoch time: 75.20028614997864ed in 0.4336s, epoch ETA: 0.4336s\t\n",
      "Epoch: 68 Train Metrics:\n",
      " acc: 0.867 log loss: 0.325 \t f1: 0.417 \t rmse: 0.315 \t auc: 0.837 \t r2: 0.272 \n",
      "\n",
      "Running epoch 69...\n",
      "Batch 1650 to 1660 (0.994%) completed in 0.4292s, epoch ETA: 0.4292s\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjsarsa/duolingo_dkt/code/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/sjsarsa/duolingo_dkt/code/tf/lib/python3.6/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 75.32687973976135\n",
      "Epoch: 69 Train Metrics:\n",
      " acc: 0.867 log loss: nan \t f1: 0.418 \t rmse: 0.314 \t auc: 0.837 \t r2: 0.273 \n",
      "\n",
      "Running epoch 70...\n",
      "Total epoch time: 75.16026902198792ed in 0.4297s, epoch ETA: 0.4297s\t\n",
      "Epoch: 70 Train Metrics:\n",
      " acc: 0.867 log loss: 0.324 \t f1: 0.420 \t rmse: 0.314 \t auc: 0.838 \t r2: 0.274 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.24901223182678ed in 0.355s, epoch ETA: 0.1775s\t\t\n",
      "Epoch: 70 Test Metrics:\n",
      " acc: 0.848 \t log loss: 0.367 \t f1: 0.381 \t rmse: 0.337 \t auc: 0.803 \t r2: 0.221\n",
      "**********\n",
      "Running epoch 71...\n",
      "Total epoch time: 75.49891328811646ed in 0.4389s, epoch ETA: 0.4389s\t\n",
      "Epoch: 71 Train Metrics:\n",
      " acc: 0.867 log loss: 0.324 \t f1: 0.419 \t rmse: 0.314 \t auc: 0.838 \t r2: 0.274 \n",
      "\n",
      "Running epoch 72...\n",
      "Total epoch time: 75.24097776412964ed in 0.4428s, epoch ETA: 0.4428s\t\n",
      "Epoch: 72 Train Metrics:\n",
      " acc: 0.868 log loss: 0.324 \t f1: 0.420 \t rmse: 0.314 \t auc: 0.838 \t r2: 0.274 \n",
      "\n",
      "Running epoch 73...\n",
      "Total epoch time: 75.1123616695404ted in 0.4343s, epoch ETA: 0.4343s\t\n",
      "Epoch: 73 Train Metrics:\n",
      " acc: 0.867 log loss: 0.324 \t f1: 0.417 \t rmse: 0.315 \t auc: 0.837 \t r2: 0.272 \n",
      "\n",
      "Running epoch 74...\n",
      "Total epoch time: 75.3916597366333ted in 0.4448s, epoch ETA: 0.4448s\t\n",
      "Epoch: 74 Train Metrics:\n",
      " acc: 0.868 log loss: 0.323 \t f1: 0.421 \t rmse: 0.314 \t auc: 0.839 \t r2: 0.276 \n",
      "\n",
      "Running epoch 75...\n",
      "Total epoch time: 75.15073013305664ed in 0.4449s, epoch ETA: 0.4449s\t\n",
      "Epoch: 75 Train Metrics:\n",
      " acc: 0.868 log loss: 0.323 \t f1: 0.424 \t rmse: 0.314 \t auc: 0.839 \t r2: 0.277 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.863529682159424d in 0.3449s, epoch ETA: 0.1724s\t\n",
      "Epoch: 75 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.366 \t f1: 0.388 \t rmse: 0.336 \t auc: 0.804 \t r2: 0.222\n",
      "**********\n",
      "Running epoch 76...\n",
      "Total epoch time: 75.17516374588013ed in 0.4431s, epoch ETA: 0.4431s\t\n",
      "Epoch: 76 Train Metrics:\n",
      " acc: 0.868 log loss: 0.323 \t f1: 0.425 \t rmse: 0.314 \t auc: 0.839 \t r2: 0.275 \n",
      "\n",
      "Running epoch 77...\n",
      "Total epoch time: 75.42798566818237ed in 0.4489s, epoch ETA: 0.4489s\t\n",
      "Epoch: 77 Train Metrics:\n",
      " acc: 0.868 log loss: 0.322 \t f1: 0.425 \t rmse: 0.313 \t auc: 0.840 \t r2: 0.278 \n",
      "\n",
      "Running epoch 78...\n",
      "Total epoch time: 75.56415510177612ed in 0.4435s, epoch ETA: 0.4435s\t\n",
      "Epoch: 78 Train Metrics:\n",
      " acc: 0.868 log loss: 0.322 \t f1: 0.425 \t rmse: 0.313 \t auc: 0.840 \t r2: 0.278 \n",
      "\n",
      "Running epoch 79...\n",
      "Total epoch time: 75.36800837516785ed in 0.4364s, epoch ETA: 0.4364s\t\n",
      "Epoch: 79 Train Metrics:\n",
      " acc: 0.868 log loss: 0.322 \t f1: 0.426 \t rmse: 0.313 \t auc: 0.841 \t r2: 0.279 \n",
      "\n",
      "Running epoch 80...\n",
      "Total epoch time: 75.7265214920044ted in 0.4483s, epoch ETA: 0.4483s\t\n",
      "Epoch: 80 Train Metrics:\n",
      " acc: 0.868 log loss: nan \t f1: 0.424 \t rmse: 0.314 \t auc: 0.838 \t r2: 0.275 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.96833634376526ed in 0.3521s, epoch ETA: 0.1761s\t\n",
      "Epoch: 80 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.367 \t f1: 0.367 \t rmse: 0.336 \t auc: 0.804 \t r2: 0.222\n",
      "**********\n",
      "Running epoch 81...\n",
      "Total epoch time: 75.28510332107544ed in 0.4244s, epoch ETA: 0.4244s\t\n",
      "Epoch: 81 Train Metrics:\n",
      " acc: 0.868 log loss: nan \t f1: 0.427 \t rmse: 0.313 \t auc: 0.841 \t r2: 0.280 \n",
      "\n",
      "Running epoch 82...\n",
      "Total epoch time: 75.27727055549622ed in 0.4132s, epoch ETA: 0.4132s\t\n",
      "Epoch: 82 Train Metrics:\n",
      " acc: 0.868 log loss: 0.322 \t f1: 0.427 \t rmse: 0.313 \t auc: 0.841 \t r2: 0.279 \n",
      "\n",
      "Running epoch 83...\n",
      "Total epoch time: 75.41104674339294ed in 0.4475s, epoch ETA: 0.4475s\t\n",
      "Epoch: 83 Train Metrics:\n",
      " acc: 0.869 log loss: 0.321 \t f1: 0.430 \t rmse: 0.313 \t auc: 0.842 \t r2: 0.281 \n",
      "\n",
      "Running epoch 84...\n",
      "Total epoch time: 75.21464896202087ed in 0.4418s, epoch ETA: 0.4418s\t\n",
      "Epoch: 84 Train Metrics:\n",
      " acc: 0.868 log loss: nan \t f1: 0.424 \t rmse: 0.313 \t auc: 0.839 \t r2: 0.277 \n",
      "\n",
      "Running epoch 85...\n",
      "Total epoch time: 75.27061223983765ed in 0.4309s, epoch ETA: 0.4309s\t\n",
      "Epoch: 85 Train Metrics:\n",
      " acc: 0.869 log loss: 0.321 \t f1: 0.430 \t rmse: 0.313 \t auc: 0.841 \t r2: 0.281 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.92743682861328ed in 0.3446s, epoch ETA: 0.1723s\t\n",
      "Epoch: 85 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.366 \t f1: 0.377 \t rmse: 0.336 \t auc: 0.805 \t r2: 0.224\n",
      "**********\n",
      "Running epoch 86...\n",
      "Total epoch time: 75.28087639808655ed in 0.4428s, epoch ETA: 0.4428s\t\n",
      "Epoch: 86 Train Metrics:\n",
      " acc: 0.868 log loss: 0.322 \t f1: 0.428 \t rmse: 0.313 \t auc: 0.840 \t r2: 0.279 \n",
      "\n",
      "Running epoch 87...\n",
      "Total epoch time: 75.2877676486969ted in 0.4368s, epoch ETA: 0.4368s\t\n",
      "Epoch: 87 Train Metrics:\n",
      " acc: 0.869 log loss: 0.320 \t f1: 0.431 \t rmse: 0.312 \t auc: 0.842 \t r2: 0.282 \n",
      "\n",
      "Running epoch 88...\n",
      "Total epoch time: 75.274986743927eted in 0.4365s, epoch ETA: 0.4365s\t\n",
      "Epoch: 88 Train Metrics:\n",
      " acc: 0.869 log loss: 0.320 \t f1: 0.433 \t rmse: 0.312 \t auc: 0.843 \t r2: 0.283 \n",
      "\n",
      "Running epoch 89...\n",
      "Total epoch time: 75.44567966461182ed in 0.4485s, epoch ETA: 0.4486s\t\n",
      "Epoch: 89 Train Metrics:\n",
      " acc: 0.869 log loss: nan \t f1: 0.434 \t rmse: 0.312 \t auc: 0.842 \t r2: 0.282 \n",
      "\n",
      "Running epoch 90...\n",
      "Total epoch time: 75.27626848220825ed in 0.4232s, epoch ETA: 0.4232s\t\n",
      "Epoch: 90 Train Metrics:\n",
      " acc: 0.869 log loss: nan \t f1: 0.433 \t rmse: 0.312 \t auc: 0.843 \t r2: 0.283 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.23564648628235ed in 0.3557s, epoch ETA: 0.1779s\t\n",
      "Epoch: 90 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.365 \t f1: 0.381 \t rmse: 0.335 \t auc: 0.806 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 91...\n",
      "Total epoch time: 75.22909760475159ed in 0.4454s, epoch ETA: 0.4454s\t\n",
      "Epoch: 91 Train Metrics:\n",
      " acc: 0.869 log loss: nan \t f1: 0.435 \t rmse: 0.312 \t auc: 0.843 \t r2: 0.285 \n",
      "\n",
      "Running epoch 92...\n",
      "Total epoch time: 75.4544312953949ted in 0.4446s, epoch ETA: 0.4446s\t\n",
      "Epoch: 92 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.436 \t rmse: 0.312 \t auc: 0.844 \t r2: 0.285 \n",
      "\n",
      "Running epoch 93...\n",
      "Total epoch time: 75.28679656982422ed in 0.4375s, epoch ETA: 0.4375s\t\n",
      "Epoch: 93 Train Metrics:\n",
      " acc: 0.870 log loss: 0.319 \t f1: 0.437 \t rmse: 0.312 \t auc: 0.844 \t r2: 0.285 \n",
      "\n",
      "Running epoch 94...\n",
      "Total epoch time: 75.13313508033752ed in 0.4154s, epoch ETA: 0.4154s\t\n",
      "Epoch: 94 Train Metrics:\n",
      " acc: 0.869 log loss: nan \t f1: 0.438 \t rmse: 0.312 \t auc: 0.844 \t r2: 0.285 \n",
      "\n",
      "Running epoch 95...\n",
      "Total epoch time: 75.39404249191284ed in 0.4274s, epoch ETA: 0.4274s\t\n",
      "Epoch: 95 Train Metrics:\n",
      " acc: 0.870 log loss: 0.319 \t f1: 0.437 \t rmse: 0.312 \t auc: 0.844 \t r2: 0.286 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.95307493209839ed in 0.3551s, epoch ETA: 0.1776s\t\n",
      "Epoch: 95 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.367 \t f1: 0.367 \t rmse: 0.336 \t auc: 0.805 \t r2: 0.224\n",
      "**********\n",
      "Running epoch 96...\n",
      "Total epoch time: 75.39157199859619ed in 0.4394s, epoch ETA: 0.4394s\t\n",
      "Epoch: 96 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.439 \t rmse: 0.311 \t auc: 0.845 \t r2: 0.287 \n",
      "\n",
      "Running epoch 97...\n",
      "Total epoch time: 75.20426416397095ed in 0.4391s, epoch ETA: 0.4391s\t\n",
      "Epoch: 97 Train Metrics:\n",
      " acc: 0.870 log loss: 0.318 \t f1: 0.440 \t rmse: 0.311 \t auc: 0.845 \t r2: 0.288 \n",
      "\n",
      "Running epoch 98...\n",
      "Total epoch time: 75.17469906806946ed in 0.4399s, epoch ETA: 0.4399s\t\n",
      "Epoch: 98 Train Metrics:\n",
      " acc: 0.870 log loss: 0.318 \t f1: 0.440 \t rmse: 0.311 \t auc: 0.845 \t r2: 0.287 \n",
      "\n",
      "Running epoch 99...\n",
      "Total epoch time: 75.1754994392395ted in 0.4378s, epoch ETA: 0.4378s\t\n",
      "Epoch: 99 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.440 \t rmse: 0.311 \t auc: 0.845 \t r2: 0.287 \n",
      "\n",
      "Running epoch 100...\n",
      "Total epoch time: 75.28732490539551ed in 0.4479s, epoch ETA: 0.4479s\t\n",
      "Epoch: 100 Train Metrics:\n",
      " acc: 0.870 log loss: 0.318 \t f1: 0.439 \t rmse: 0.311 \t auc: 0.845 \t r2: 0.288 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.9317307472229ted in 0.3472s, epoch ETA: 0.1736s\t\n",
      "Epoch: 100 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.368 \t f1: 0.366 \t rmse: 0.336 \t auc: 0.804 \t r2: 0.222\n",
      "**********\n",
      "Running epoch 101...\n",
      "Total epoch time: 75.25509357452393ed in 0.4384s, epoch ETA: 0.4384s\t\n",
      "Epoch: 101 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.443 \t rmse: 0.311 \t auc: 0.846 \t r2: 0.289 \n",
      "\n",
      "Running epoch 102...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 75.2882719039917ted in 0.4436s, epoch ETA: 0.4436s\t\n",
      "Epoch: 102 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.443 \t rmse: 0.311 \t auc: 0.846 \t r2: 0.290 \n",
      "\n",
      "Running epoch 103...\n",
      "Total epoch time: 75.38475704193115ed in 0.436s, epoch ETA: 0.436s\t\t\n",
      "Epoch: 103 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.442 \t rmse: 0.311 \t auc: 0.846 \t r2: 0.289 \n",
      "\n",
      "Running epoch 104...\n",
      "Total epoch time: 75.59557127952576ed in 0.4523s, epoch ETA: 0.4523s\t\n",
      "Epoch: 104 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.444 \t rmse: 0.311 \t auc: 0.846 \t r2: 0.290 \n",
      "\n",
      "Running epoch 105...\n",
      "Total epoch time: 75.2270622253418ted in 0.4233s, epoch ETA: 0.4233s\t\n",
      "Epoch: 105 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.444 \t rmse: 0.310 \t auc: 0.847 \t r2: 0.291 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.16804504394531ed in 0.3468s, epoch ETA: 0.1734s\t\n",
      "Epoch: 105 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.365 \t f1: 0.403 \t rmse: 0.335 \t auc: 0.806 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 106...\n",
      "Total epoch time: 75.0547981262207ted in 0.4434s, epoch ETA: 0.4434s\t\n",
      "Epoch: 106 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.445 \t rmse: 0.310 \t auc: 0.847 \t r2: 0.292 \n",
      "\n",
      "Running epoch 107...\n",
      "Total epoch time: 75.40868973731995ed in 0.4414s, epoch ETA: 0.4414s\t\n",
      "Epoch: 107 Train Metrics:\n",
      " acc: 0.870 log loss: nan \t f1: 0.445 \t rmse: 0.311 \t auc: 0.847 \t r2: 0.291 \n",
      "\n",
      "Running epoch 108...\n",
      "Total epoch time: 75.32128691673279ed in 0.4436s, epoch ETA: 0.4436s\t\n",
      "Epoch: 108 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.445 \t rmse: 0.310 \t auc: 0.847 \t r2: 0.291 \n",
      "\n",
      "Running epoch 109...\n",
      "Total epoch time: 75.29757618904114ed in 0.4396s, epoch ETA: 0.4396s\t\n",
      "Epoch: 109 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.447 \t rmse: 0.310 \t auc: 0.847 \t r2: 0.292 \n",
      "\n",
      "Running epoch 110...\n",
      "Total epoch time: 75.39968824386597ed in 0.4342s, epoch ETA: 0.4342s\t\n",
      "Epoch: 110 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.446 \t rmse: 0.310 \t auc: 0.848 \t r2: 0.293 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.92568755149841ed in 0.3514s, epoch ETA: 0.1757s\t\n",
      "Epoch: 110 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.365 \t f1: 0.394 \t rmse: 0.335 \t auc: 0.806 \t r2: 0.228\n",
      "**********\n",
      "Running epoch 111...\n",
      "Total epoch time: 75.09260177612305ed in 0.4469s, epoch ETA: 0.4469s\t\n",
      "Epoch: 111 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.448 \t rmse: 0.310 \t auc: 0.847 \t r2: 0.292 \n",
      "\n",
      "Running epoch 112...\n",
      "Total epoch time: 75.21359944343567ed in 0.4459s, epoch ETA: 0.4459s\t\n",
      "Epoch: 112 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.447 \t rmse: 0.310 \t auc: 0.847 \t r2: 0.293 \n",
      "\n",
      "Running epoch 113...\n",
      "Total epoch time: 75.38213992118835ed in 0.4452s, epoch ETA: 0.4452s\t\n",
      "Epoch: 113 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.449 \t rmse: 0.310 \t auc: 0.848 \t r2: 0.294 \n",
      "\n",
      "Running epoch 114...\n",
      "Total epoch time: 75.25443196296692ed in 0.4468s, epoch ETA: 0.4468s\t\n",
      "Epoch: 114 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.449 \t rmse: 0.310 \t auc: 0.848 \t r2: 0.294 \n",
      "\n",
      "Running epoch 115...\n",
      "Total epoch time: 75.3273811340332ted in 0.4427s, epoch ETA: 0.4427s\t\n",
      "Epoch: 115 Train Metrics:\n",
      " acc: 0.871 log loss: 0.315 \t f1: 0.451 \t rmse: 0.309 \t auc: 0.849 \t r2: 0.296 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.95821189880371ed in 0.3448s, epoch ETA: 0.1724s\t\n",
      "Epoch: 115 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.364 \t f1: 0.392 \t rmse: 0.335 \t auc: 0.807 \t r2: 0.229\n",
      "**********\n",
      "Running epoch 116...\n",
      "Total epoch time: 75.47034406661987ed in 0.4375s, epoch ETA: 0.4375s\t\n",
      "Epoch: 116 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.452 \t rmse: 0.309 \t auc: 0.849 \t r2: 0.296 \n",
      "\n",
      "Running epoch 117...\n",
      "Total epoch time: 75.2389464378357ted in 0.4347s, epoch ETA: 0.4347s\t\n",
      "Epoch: 117 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.450 \t rmse: 0.310 \t auc: 0.849 \t r2: 0.295 \n",
      "\n",
      "Running epoch 118...\n",
      "Total epoch time: 75.41783022880554ed in 0.4389s, epoch ETA: 0.4389s\t\n",
      "Epoch: 118 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.454 \t rmse: 0.309 \t auc: 0.849 \t r2: 0.297 \n",
      "\n",
      "Running epoch 119...\n",
      "Total epoch time: 75.37718272209167ed in 0.422s, epoch ETA: 0.422s\ts\t\n",
      "Epoch: 119 Train Metrics:\n",
      " acc: 0.871 log loss: 0.315 \t f1: 0.451 \t rmse: 0.310 \t auc: 0.848 \t r2: 0.294 \n",
      "\n",
      "Running epoch 120...\n",
      "Total epoch time: 75.29049324989319ed in 0.4424s, epoch ETA: 0.4424s\t\n",
      "Epoch: 120 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.451 \t rmse: 0.310 \t auc: 0.849 \t r2: 0.295 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.084107398986816d in 0.3578s, epoch ETA: 0.1789s\t\n",
      "Epoch: 120 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.366 \t f1: 0.377 \t rmse: 0.335 \t auc: 0.805 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 121...\n",
      "Total epoch time: 75.22821068763733ed in 0.4386s, epoch ETA: 0.4386s\t\n",
      "Epoch: 121 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.450 \t rmse: 0.310 \t auc: 0.848 \t r2: 0.294 \n",
      "\n",
      "Running epoch 122...\n",
      "Total epoch time: 75.3689169883728ted in 0.442s, epoch ETA: 0.442s\ts\t\n",
      "Epoch: 122 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.450 \t rmse: 0.310 \t auc: 0.848 \t r2: 0.295 \n",
      "\n",
      "Running epoch 123...\n",
      "Total epoch time: 75.12470269203186ed in 0.4399s, epoch ETA: 0.4399s\t\n",
      "Epoch: 123 Train Metrics:\n",
      " acc: 0.871 log loss: nan \t f1: 0.451 \t rmse: 0.309 \t auc: 0.849 \t r2: 0.296 \n",
      "\n",
      "Running epoch 124...\n",
      "Total epoch time: 75.21042370796204ed in 0.451s, epoch ETA: 0.451s\ts\t\n",
      "Epoch: 124 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.453 \t rmse: 0.309 \t auc: 0.850 \t r2: 0.298 \n",
      "\n",
      "Running epoch 125...\n",
      "Total epoch time: 75.26256775856018ed in 0.4377s, epoch ETA: 0.4377s\t\n",
      "Epoch: 125 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.454 \t rmse: 0.309 \t auc: 0.850 \t r2: 0.298 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.0261344909668ted in 0.3395s, epoch ETA: 0.1698s\t\n",
      "Epoch: 125 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.365 \t f1: 0.405 \t rmse: 0.335 \t auc: 0.806 \t r2: 0.228\n",
      "**********\n",
      "Running epoch 126...\n",
      "Total epoch time: 75.31352949142456ed in 0.4431s, epoch ETA: 0.4431s\t\n",
      "Epoch: 126 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.455 \t rmse: 0.309 \t auc: 0.850 \t r2: 0.299 \n",
      "\n",
      "Running epoch 127...\n",
      "Total epoch time: 75.27640867233276ed in 0.4411s, epoch ETA: 0.4411s\t\n",
      "Epoch: 127 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.458 \t rmse: 0.309 \t auc: 0.851 \t r2: 0.300 \n",
      "\n",
      "Running epoch 128...\n",
      "Total epoch time: 75.23253750801086ed in 0.4397s, epoch ETA: 0.4397s\t\n",
      "Epoch: 128 Train Metrics:\n",
      " acc: 0.872 log loss: 0.313 \t f1: 0.458 \t rmse: 0.309 \t auc: 0.851 \t r2: 0.299 \n",
      "\n",
      "Running epoch 129...\n",
      "Total epoch time: 75.1756911277771ted in 0.4423s, epoch ETA: 0.4423s\t\n",
      "Epoch: 129 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.456 \t rmse: 0.309 \t auc: 0.850 \t r2: 0.299 \n",
      "\n",
      "Running epoch 130...\n",
      "Total epoch time: 75.28046345710754ed in 0.4141s, epoch ETA: 0.4141s\t\n",
      "Epoch: 130 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.458 \t rmse: 0.308 \t auc: 0.851 \t r2: 0.300 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.19607138633728ed in 0.344s, epoch ETA: 0.172s\ts\t\n",
      "Epoch: 130 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.366 \t f1: 0.401 \t rmse: 0.335 \t auc: 0.805 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 131...\n",
      "Total epoch time: 75.32172679901123ed in 0.438s, epoch ETA: 0.438s\ts\t\n",
      "Epoch: 131 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.457 \t rmse: 0.309 \t auc: 0.850 \t r2: 0.299 \n",
      "\n",
      "Running epoch 132...\n",
      "Total epoch time: 75.1004786491394ted in 0.4386s, epoch ETA: 0.4386s\t\n",
      "Epoch: 132 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.458 \t rmse: 0.308 \t auc: 0.852 \t r2: 0.301 \n",
      "\n",
      "Running epoch 133...\n",
      "Total epoch time: 75.19833707809448ed in 0.4389s, epoch ETA: 0.4389s\t\n",
      "Epoch: 133 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.459 \t rmse: 0.308 \t auc: 0.852 \t r2: 0.301 \n",
      "\n",
      "Running epoch 134...\n",
      "Total epoch time: 75.12968349456787ed in 0.4368s, epoch ETA: 0.4368s\t\n",
      "Epoch: 134 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.458 \t rmse: 0.308 \t auc: 0.851 \t r2: 0.300 \n",
      "\n",
      "Running epoch 135...\n",
      "Total epoch time: 75.44717144966125ed in 0.4282s, epoch ETA: 0.4282s\t\n",
      "Epoch: 135 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.460 \t rmse: 0.308 \t auc: 0.852 \t r2: 0.302 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 48.35918951034546ed in 0.3592s, epoch ETA: 0.1796s\t\n",
      "Epoch: 135 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.364 \t f1: 0.404 \t rmse: 0.335 \t auc: 0.807 \t r2: 0.230\n",
      "**********\n",
      "Running epoch 136...\n",
      "Total epoch time: 75.04819130897522ed in 0.427s, epoch ETA: 0.427s\ts\t\n",
      "Epoch: 136 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.462 \t rmse: 0.308 \t auc: 0.852 \t r2: 0.303 \n",
      "\n",
      "Running epoch 137...\n",
      "Total epoch time: 75.40665602684021ed in 0.4456s, epoch ETA: 0.4456s\t\n",
      "Epoch: 137 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.459 \t rmse: 0.308 \t auc: 0.852 \t r2: 0.302 \n",
      "\n",
      "Running epoch 138...\n",
      "Total epoch time: 75.14399361610413ed in 0.4346s, epoch ETA: 0.4346s\t\n",
      "Epoch: 138 Train Metrics:\n",
      " acc: 0.872 log loss: nan \t f1: 0.460 \t rmse: 0.308 \t auc: 0.853 \t r2: 0.303 \n",
      "\n",
      "Running epoch 139...\n",
      "Total epoch time: 75.21467018127441ed in 0.4404s, epoch ETA: 0.4404s\t\n",
      "Epoch: 139 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.462 \t rmse: 0.308 \t auc: 0.852 \t r2: 0.303 \n",
      "\n",
      "Running epoch 140...\n",
      "Total epoch time: 75.13055944442749ed in 0.446s, epoch ETA: 0.446s\ts\t\n",
      "Epoch: 140 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.462 \t rmse: 0.308 \t auc: 0.853 \t r2: 0.304 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.915305852890015d in 0.3503s, epoch ETA: 0.1752s\t\n",
      "Epoch: 140 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.368 \t f1: 0.375 \t rmse: 0.336 \t auc: 0.805 \t r2: 0.225\n",
      "**********\n",
      "Running epoch 141...\n",
      "Total epoch time: 75.49555015563965ed in 0.4405s, epoch ETA: 0.4405s\t\n",
      "Epoch: 141 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.464 \t rmse: 0.308 \t auc: 0.853 \t r2: 0.304 \n",
      "\n",
      "Running epoch 142...\n",
      "Total epoch time: 75.28788137435913ed in 0.4476s, epoch ETA: 0.4476s\t\n",
      "Epoch: 142 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.463 \t rmse: 0.308 \t auc: 0.853 \t r2: 0.303 \n",
      "\n",
      "Running epoch 143...\n",
      "Total epoch time: 75.25903177261353ed in 0.4261s, epoch ETA: 0.4261s\t\n",
      "Epoch: 143 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.461 \t rmse: 0.308 \t auc: 0.852 \t r2: 0.303 \n",
      "\n",
      "Running epoch 144...\n",
      "Total epoch time: 75.35607767105103ed in 0.4415s, epoch ETA: 0.4415s\t\n",
      "Epoch: 144 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.463 \t rmse: 0.307 \t auc: 0.853 \t r2: 0.305 \n",
      "\n",
      "Running epoch 145...\n",
      "Total epoch time: 75.06468033790588ed in 0.4365s, epoch ETA: 0.4365s\t\n",
      "Epoch: 145 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.465 \t rmse: 0.307 \t auc: 0.854 \t r2: 0.306 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.08111500740051ed in 0.3446s, epoch ETA: 0.1723s\t\n",
      "Epoch: 145 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.364 \t f1: 0.404 \t rmse: 0.334 \t auc: 0.807 \t r2: 0.231\n",
      "**********\n",
      "Running epoch 146...\n",
      "Total epoch time: 75.34576654434204ed in 0.4437s, epoch ETA: 0.4437s\t\n",
      "Epoch: 146 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.465 \t rmse: 0.307 \t auc: 0.853 \t r2: 0.305 \n",
      "\n",
      "Running epoch 147...\n",
      "Total epoch time: 75.25206279754639ed in 0.4431s, epoch ETA: 0.4431s\t\n",
      "Epoch: 147 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.465 \t rmse: 0.307 \t auc: 0.854 \t r2: 0.307 \n",
      "\n",
      "Running epoch 148...\n",
      "Total epoch time: 75.5779492855072ted in 0.4237s, epoch ETA: 0.4237s\t\n",
      "Epoch: 148 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.466 \t rmse: 0.307 \t auc: 0.854 \t r2: 0.307 \n",
      "\n",
      "Running epoch 149...\n",
      "Total epoch time: 75.12384104728699ed in 0.4164s, epoch ETA: 0.4164s\t\n",
      "Epoch: 149 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.465 \t rmse: 0.307 \t auc: 0.854 \t r2: 0.306 \n",
      "\n",
      "Running epoch 150...\n",
      "Total epoch time: 75.29459261894226ed in 0.4299s, epoch ETA: 0.4299s\t\n",
      "Epoch: 150 Train Metrics:\n",
      " acc: 0.873 log loss: 0.310 \t f1: 0.467 \t rmse: 0.307 \t auc: 0.854 \t r2: 0.307 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.04167366027832ed in 0.3473s, epoch ETA: 0.1736s\t\n",
      "Epoch: 150 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.365 \t f1: 0.382 \t rmse: 0.334 \t auc: 0.808 \t r2: 0.230\n",
      "**********\n",
      "Running epoch 151...\n",
      "Total epoch time: 74.93315887451172ed in 0.425s, epoch ETA: 0.425s\ts\t\n",
      "Epoch: 151 Train Metrics:\n",
      " acc: 0.873 log loss: nan \t f1: 0.467 \t rmse: 0.307 \t auc: 0.854 \t r2: 0.307 \n",
      "\n",
      "Running epoch 152...\n",
      "Total epoch time: 75.32495784759521ed in 0.4453s, epoch ETA: 0.4453s\t\n",
      "Epoch: 152 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.469 \t rmse: 0.307 \t auc: 0.855 \t r2: 0.308 \n",
      "\n",
      "Running epoch 153...\n",
      "Total epoch time: 75.45273423194885ed in 0.4408s, epoch ETA: 0.4408s\t\n",
      "Epoch: 153 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.468 \t rmse: 0.307 \t auc: 0.855 \t r2: 0.309 \n",
      "\n",
      "Running epoch 154...\n",
      "Total epoch time: 75.42921376228333ed in 0.438s, epoch ETA: 0.438s\ts\t\n",
      "Epoch: 154 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.469 \t rmse: 0.307 \t auc: 0.855 \t r2: 0.309 \n",
      "\n",
      "Running epoch 155...\n",
      "Total epoch time: 75.46867561340332ed in 0.4256s, epoch ETA: 0.4256s\t\n",
      "Epoch: 155 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.469 \t rmse: 0.307 \t auc: 0.854 \t r2: 0.308 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.07308268547058ed in 0.3458s, epoch ETA: 0.1729s\t\n",
      "Epoch: 155 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.364 \t f1: 0.392 \t rmse: 0.334 \t auc: 0.807 \t r2: 0.231\n",
      "**********\n",
      "Running epoch 156...\n",
      "Total epoch time: 75.20284962654114ed in 0.4377s, epoch ETA: 0.4377s\t\n",
      "Epoch: 156 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.470 \t rmse: 0.306 \t auc: 0.856 \t r2: 0.310 \n",
      "\n",
      "Running epoch 157...\n",
      "Total epoch time: 75.30729603767395ed in 0.4448s, epoch ETA: 0.4448s\t\n",
      "Epoch: 157 Train Metrics:\n",
      " acc: 0.874 log loss: 0.308 \t f1: 0.471 \t rmse: 0.306 \t auc: 0.856 \t r2: 0.310 \n",
      "\n",
      "Running epoch 158...\n",
      "Total epoch time: 75.34444308280945ed in 0.4397s, epoch ETA: 0.4397s\t\n",
      "Epoch: 158 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.470 \t rmse: 0.306 \t auc: 0.855 \t r2: 0.309 \n",
      "\n",
      "Running epoch 159...\n",
      "Total epoch time: 75.17065334320068ed in 0.4461s, epoch ETA: 0.4461s\t\n",
      "Epoch: 159 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.471 \t rmse: 0.306 \t auc: 0.856 \t r2: 0.310 \n",
      "\n",
      "Running epoch 160...\n",
      "Total epoch time: 75.40989875793457ed in 0.4263s, epoch ETA: 0.4263s\t\n",
      "Epoch: 160 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.470 \t rmse: 0.306 \t auc: 0.856 \t r2: 0.311 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.12817144393921ed in 0.3442s, epoch ETA: 0.1721s\t\n",
      "Epoch: 160 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.364 \t f1: 0.402 \t rmse: 0.334 \t auc: 0.808 \t r2: 0.232\n",
      "**********\n",
      "Running epoch 161...\n",
      "Total epoch time: 75.47205448150635ed in 0.4478s, epoch ETA: 0.4478s\t\n",
      "Epoch: 161 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.472 \t rmse: 0.306 \t auc: 0.856 \t r2: 0.311 \n",
      "\n",
      "Running epoch 162...\n",
      "Total epoch time: 75.26074433326721ed in 0.4415s, epoch ETA: 0.4415s\t\n",
      "Epoch: 162 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.472 \t rmse: 0.306 \t auc: 0.857 \t r2: 0.312 \n",
      "\n",
      "Running epoch 163...\n",
      "Total epoch time: 75.13210535049438ed in 0.4274s, epoch ETA: 0.4274s\t\n",
      "Epoch: 163 Train Metrics:\n",
      " acc: 0.874 log loss: 0.308 \t f1: 0.472 \t rmse: 0.306 \t auc: 0.857 \t r2: 0.312 \n",
      "\n",
      "Running epoch 164...\n",
      "Total epoch time: 75.13718390464783ed in 0.4181s, epoch ETA: 0.4181s\t\n",
      "Epoch: 164 Train Metrics:\n",
      " acc: 0.874 log loss: 0.308 \t f1: 0.471 \t rmse: 0.306 \t auc: 0.856 \t r2: 0.311 \n",
      "\n",
      "Running epoch 165...\n",
      "Total epoch time: 75.369624376297eted in 0.4383s, epoch ETA: 0.4383s\t\n",
      "Epoch: 165 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.474 \t rmse: 0.306 \t auc: 0.857 \t r2: 0.313 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.18033957481384ed in 0.3465s, epoch ETA: 0.1732s\t\n",
      "Epoch: 165 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.365 \t f1: 0.387 \t rmse: 0.334 \t auc: 0.807 \t r2: 0.231\n",
      "**********\n",
      "Running epoch 166...\n",
      "Total epoch time: 74.99437618255615ed in 0.4436s, epoch ETA: 0.4436s\t\n",
      "Epoch: 166 Train Metrics:\n",
      " acc: 0.874 log loss: 0.307 \t f1: 0.473 \t rmse: 0.306 \t auc: 0.857 \t r2: 0.312 \n",
      "\n",
      "Running epoch 167...\n",
      "Total epoch time: 75.22942996025085ed in 0.4463s, epoch ETA: 0.4463s\t\n",
      "Epoch: 167 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.474 \t rmse: 0.306 \t auc: 0.857 \t r2: 0.313 \n",
      "\n",
      "Running epoch 168...\n",
      "Total epoch time: 75.24342727661133ed in 0.4444s, epoch ETA: 0.4445s\t\n",
      "Epoch: 168 Train Metrics:\n",
      " acc: 0.874 log loss: nan \t f1: 0.474 \t rmse: 0.306 \t auc: 0.856 \t r2: 0.311 \n",
      "\n",
      "Running epoch 169...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 75.47207307815552ed in 0.4319s, epoch ETA: 0.4319s\t\n",
      "Epoch: 169 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.475 \t rmse: 0.305 \t auc: 0.857 \t r2: 0.314 \n",
      "\n",
      "Running epoch 170...\n",
      "Total epoch time: 74.983891248703eted in 0.4325s, epoch ETA: 0.4325s\t\n",
      "Epoch: 170 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.478 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.315 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.911972522735596d in 0.352s, epoch ETA: 0.176s\ts\t\n",
      "Epoch: 170 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.365 \t f1: 0.389 \t rmse: 0.334 \t auc: 0.808 \t r2: 0.231\n",
      "**********\n",
      "Running epoch 171...\n",
      "Total epoch time: 75.18378973007202ed in 0.4256s, epoch ETA: 0.4256s\t\n",
      "Epoch: 171 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.476 \t rmse: 0.306 \t auc: 0.857 \t r2: 0.313 \n",
      "\n",
      "Running epoch 172...\n",
      "Total epoch time: 75.28766798973083ed in 0.4397s, epoch ETA: 0.4397s\t\n",
      "Epoch: 172 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.476 \t rmse: 0.305 \t auc: 0.857 \t r2: 0.314 \n",
      "\n",
      "Running epoch 173...\n",
      "Total epoch time: 74.86813712120056ed in 0.4158s, epoch ETA: 0.4158s\t\n",
      "Epoch: 173 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.476 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.314 \n",
      "\n",
      "Running epoch 174...\n",
      "Total epoch time: 75.09541463851929ed in 0.4332s, epoch ETA: 0.4332s\t\n",
      "Epoch: 174 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.476 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.315 \n",
      "\n",
      "Running epoch 175...\n",
      "Total epoch time: 74.75881028175354ed in 0.4433s, epoch ETA: 0.4433s\t\n",
      "Epoch: 175 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.476 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.314 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.48372030258179ed in 0.3578s, epoch ETA: 0.1789s\t\n",
      "Epoch: 175 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.365 \t f1: 0.389 \t rmse: 0.334 \t auc: 0.808 \t r2: 0.231\n",
      "**********\n",
      "Running epoch 176...\n",
      "Total epoch time: 75.06801843643188ed in 0.4411s, epoch ETA: 0.4411s\t\n",
      "Epoch: 176 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.478 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.316 \n",
      "\n",
      "Running epoch 177...\n",
      "Total epoch time: 75.26719617843628ed in 0.4282s, epoch ETA: 0.4282s\t\n",
      "Epoch: 177 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.478 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.315 \n",
      "\n",
      "Running epoch 178...\n",
      "Total epoch time: 75.11774754524231ed in 0.4355s, epoch ETA: 0.4355s\t\n",
      "Epoch: 178 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.478 \t rmse: 0.305 \t auc: 0.859 \t r2: 0.317 \n",
      "\n",
      "Running epoch 179...\n",
      "Total epoch time: 75.2843873500824ted in 0.4502s, epoch ETA: 0.4502s\t\n",
      "Epoch: 179 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.479 \t rmse: 0.305 \t auc: 0.859 \t r2: 0.317 \n",
      "\n",
      "Running epoch 180...\n",
      "Total epoch time: 75.54285907745361ed in 0.4426s, epoch ETA: 0.4426s\t\n",
      "Epoch: 180 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.479 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.316 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.01100778579712ed in 0.3538s, epoch ETA: 0.1769s\t\n",
      "Epoch: 180 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.366 \t f1: 0.416 \t rmse: 0.335 \t auc: 0.805 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 181...\n",
      "Total epoch time: 75.18778419494629ed in 0.4394s, epoch ETA: 0.4394s\t\n",
      "Epoch: 181 Train Metrics:\n",
      " acc: 0.875 log loss: 0.306 \t f1: 0.477 \t rmse: 0.305 \t auc: 0.859 \t r2: 0.316 \n",
      "\n",
      "Running epoch 182...\n",
      "Total epoch time: 75.30448246002197ed in 0.4478s, epoch ETA: 0.4478s\t\n",
      "Epoch: 182 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.478 \t rmse: 0.305 \t auc: 0.859 \t r2: 0.317 \n",
      "\n",
      "Running epoch 183...\n",
      "Total epoch time: 75.37191438674927ed in 0.442s, epoch ETA: 0.442s\ts\t\n",
      "Epoch: 183 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.479 \t rmse: 0.305 \t auc: 0.859 \t r2: 0.317 \n",
      "\n",
      "Running epoch 184...\n",
      "Total epoch time: 75.08619737625122ed in 0.434s, epoch ETA: 0.434s\ts\t\n",
      "Epoch: 184 Train Metrics:\n",
      " acc: 0.875 log loss: 0.306 \t f1: 0.479 \t rmse: 0.305 \t auc: 0.858 \t r2: 0.316 \n",
      "\n",
      "Running epoch 185...\n",
      "Total epoch time: 74.89434170722961ed in 0.4168s, epoch ETA: 0.4168s\t\n",
      "Epoch: 185 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.481 \t rmse: 0.304 \t auc: 0.860 \t r2: 0.319 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.47571134567261ed in 0.3471s, epoch ETA: 0.1736s\t\n",
      "Epoch: 185 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.366 \t f1: 0.391 \t rmse: 0.335 \t auc: 0.807 \t r2: 0.229\n",
      "**********\n",
      "Running epoch 186...\n",
      "Total epoch time: 75.26088738441467ed in 0.4216s, epoch ETA: 0.4216s\t\n",
      "Epoch: 186 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.480 \t rmse: 0.304 \t auc: 0.860 \t r2: 0.319 \n",
      "\n",
      "Running epoch 187...\n",
      "Total epoch time: 75.05839514732361ed in 0.439s, epoch ETA: 0.439s\ts\t\n",
      "Epoch: 187 Train Metrics:\n",
      " acc: 0.875 log loss: nan \t f1: 0.482 \t rmse: 0.304 \t auc: 0.860 \t r2: 0.318 \n",
      "\n",
      "Running epoch 188...\n",
      "Total epoch time: 75.22493171691895ed in 0.449s, epoch ETA: 0.449s\ts\t\n",
      "Epoch: 188 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.482 \t rmse: 0.304 \t auc: 0.860 \t r2: 0.319 \n",
      "\n",
      "Running epoch 189...\n",
      "Total epoch time: 75.41529774665833ed in 0.4298s, epoch ETA: 0.4298s\t\n",
      "Epoch: 189 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.483 \t rmse: 0.304 \t auc: 0.860 \t r2: 0.320 \n",
      "\n",
      "Running epoch 190...\n",
      "Total epoch time: 75.14239263534546ed in 0.4397s, epoch ETA: 0.4397s\t\n",
      "Epoch: 190 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.483 \t rmse: 0.304 \t auc: 0.860 \t r2: 0.320 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.08187508583069ed in 0.3453s, epoch ETA: 0.1727s\t\n",
      "Epoch: 190 Test Metrics:\n",
      " acc: 0.851 \t log loss: 0.365 \t f1: 0.401 \t rmse: 0.335 \t auc: 0.806 \t r2: 0.229\n",
      "**********\n",
      "Running epoch 191...\n",
      "Total epoch time: 75.50696730613708ed in 0.4466s, epoch ETA: 0.4466s\t\n",
      "Epoch: 191 Train Metrics:\n",
      " acc: 0.876 log loss: 0.304 \t f1: 0.484 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.321 \n",
      "\n",
      "Running epoch 192...\n",
      "Total epoch time: 75.38086009025574ed in 0.4381s, epoch ETA: 0.4381s\t\n",
      "Epoch: 192 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.486 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.321 \n",
      "\n",
      "Running epoch 193...\n",
      "Total epoch time: 74.9615330696106ted in 0.4247s, epoch ETA: 0.4247s\t\n",
      "Epoch: 193 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.487 \t rmse: 0.303 \t auc: 0.861 \t r2: 0.323 \n",
      "\n",
      "Running epoch 194...\n",
      "Total epoch time: 75.07748579978943ed in 0.4271s, epoch ETA: 0.4271s\t\n",
      "Epoch: 194 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.485 \t rmse: 0.304 \t auc: 0.860 \t r2: 0.321 \n",
      "\n",
      "Running epoch 195...\n",
      "Total epoch time: 74.96659755706787ed in 0.4451s, epoch ETA: 0.4451s\t\n",
      "Epoch: 195 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.485 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.321 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.17290377616882ed in 0.3585s, epoch ETA: 0.1793s\t\n",
      "Epoch: 195 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.366 \t f1: 0.396 \t rmse: 0.335 \t auc: 0.806 \t r2: 0.229\n",
      "**********\n",
      "Running epoch 196...\n",
      "Total epoch time: 75.56871128082275ed in 0.4492s, epoch ETA: 0.4492s\t\n",
      "Epoch: 196 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.485 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.322 \n",
      "\n",
      "Running epoch 197...\n",
      "Total epoch time: 75.52308130264282ed in 0.4419s, epoch ETA: 0.4419s\t\n",
      "Epoch: 197 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.486 \t rmse: 0.303 \t auc: 0.862 \t r2: 0.323 \n",
      "\n",
      "Running epoch 198...\n",
      "Total epoch time: 75.29921269416809ed in 0.4433s, epoch ETA: 0.4433s\t\n",
      "Epoch: 198 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.487 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.322 \n",
      "\n",
      "Running epoch 199...\n",
      "Total epoch time: 75.0018219947815ted in 0.4421s, epoch ETA: 0.4421s\t\n",
      "Epoch: 199 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.486 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.322 \n",
      "\n",
      "Running epoch 200...\n",
      "Total epoch time: 75.52143406867981ed in 0.4393s, epoch ETA: 0.4393s\t\n",
      "Epoch: 200 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.486 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.322 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.10233497619629ed in 0.3478s, epoch ETA: 0.1739s\t\n",
      "Epoch: 200 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.366 \t f1: 0.407 \t rmse: 0.335 \t auc: 0.805 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 201...\n",
      "Total epoch time: 75.42305731773376ed in 0.4353s, epoch ETA: 0.4353s\t\n",
      "Epoch: 201 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.487 \t rmse: 0.303 \t auc: 0.861 \t r2: 0.323 \n",
      "\n",
      "Running epoch 202...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 75.21609902381897ed in 0.4409s, epoch ETA: 0.4409s\t\n",
      "Epoch: 202 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.485 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.322 \n",
      "\n",
      "Running epoch 203...\n",
      "Total epoch time: 75.45384645462036ed in 0.4357s, epoch ETA: 0.4357s\t\n",
      "Epoch: 203 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.487 \t rmse: 0.304 \t auc: 0.861 \t r2: 0.322 \n",
      "\n",
      "Running epoch 204...\n",
      "Total epoch time: 75.34532856941223ed in 0.4383s, epoch ETA: 0.4383s\t\n",
      "Epoch: 204 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.489 \t rmse: 0.303 \t auc: 0.862 \t r2: 0.325 \n",
      "\n",
      "Running epoch 205...\n",
      "Total epoch time: 75.20156145095825ed in 0.4386s, epoch ETA: 0.4386s\t\n",
      "Epoch: 205 Train Metrics:\n",
      " acc: 0.876 log loss: nan \t f1: 0.488 \t rmse: 0.303 \t auc: 0.862 \t r2: 0.324 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.026294469833374d in 0.347s, epoch ETA: 0.1735s\t\t\n",
      "Epoch: 205 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.366 \t f1: 0.406 \t rmse: 0.335 \t auc: 0.805 \t r2: 0.227\n",
      "**********\n",
      "Running epoch 206...\n",
      "Total epoch time: 75.58205199241638ed in 0.4439s, epoch ETA: 0.4439s\t\n",
      "Epoch: 206 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.303 \t auc: 0.863 \t r2: 0.326 \n",
      "\n",
      "Running epoch 207...\n",
      "Total epoch time: 75.15275549888611ed in 0.4418s, epoch ETA: 0.4418s\t\n",
      "Epoch: 207 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.489 \t rmse: 0.303 \t auc: 0.862 \t r2: 0.325 \n",
      "\n",
      "Running epoch 208...\n",
      "Total epoch time: 75.33608794212341ed in 0.4195s, epoch ETA: 0.4195s\t\n",
      "Epoch: 208 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.491 \t rmse: 0.303 \t auc: 0.862 \t r2: 0.325 \n",
      "\n",
      "Running epoch 209...\n",
      "Total epoch time: 75.32375025749207ed in 0.4375s, epoch ETA: 0.4375s\t\n",
      "Epoch: 209 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.303 \t auc: 0.862 \t r2: 0.325 \n",
      "\n",
      "Running epoch 210...\n",
      "Total epoch time: 75.14237141609192ed in 0.4444s, epoch ETA: 0.4444s\t\n",
      "Epoch: 210 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.491 \t rmse: 0.303 \t auc: 0.863 \t r2: 0.326 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.07080078125leted in 0.3547s, epoch ETA: 0.1773s\t\n",
      "Epoch: 210 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.367 \t f1: 0.405 \t rmse: 0.335 \t auc: 0.805 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 211...\n",
      "Total epoch time: 75.32178330421448ed in 0.4506s, epoch ETA: 0.4506s\t\n",
      "Epoch: 211 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.490 \t rmse: 0.303 \t auc: 0.862 \t r2: 0.325 \n",
      "\n",
      "Running epoch 212...\n",
      "Total epoch time: 75.06806683540344ed in 0.4363s, epoch ETA: 0.4363s\t\n",
      "Epoch: 212 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.303 \t auc: 0.863 \t r2: 0.325 \n",
      "\n",
      "Running epoch 213...\n",
      "Total epoch time: 75.38661026954651ed in 0.4213s, epoch ETA: 0.4213s\t\n",
      "Epoch: 213 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.303 \t auc: 0.863 \t r2: 0.326 \n",
      "\n",
      "Running epoch 214...\n",
      "Total epoch time: 75.16438627243042ed in 0.4321s, epoch ETA: 0.4321s\t\n",
      "Epoch: 214 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.490 \t rmse: 0.303 \t auc: 0.863 \t r2: 0.326 \n",
      "\n",
      "Running epoch 215...\n",
      "Total epoch time: 75.17084217071533ed in 0.4324s, epoch ETA: 0.4324s\t\n",
      "Epoch: 215 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.302 \t auc: 0.863 \t r2: 0.327 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 47.853848695755005d in 0.3465s, epoch ETA: 0.1732s\t\n",
      "Epoch: 215 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.366 \t f1: 0.411 \t rmse: 0.335 \t auc: 0.805 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 216...\n",
      "Total epoch time: 75.21016716957092ed in 0.4408s, epoch ETA: 0.4408s\t\n",
      "Epoch: 216 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.491 \t rmse: 0.303 \t auc: 0.863 \t r2: 0.326 \n",
      "\n",
      "Running epoch 217...\n",
      "Total epoch time: 75.18954420089722ed in 0.4449s, epoch ETA: 0.4449s\t\n",
      "Epoch: 217 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.490 \t rmse: 0.303 \t auc: 0.863 \t r2: 0.325 \n",
      "\n",
      "Running epoch 218...\n",
      "Total epoch time: 75.62531757354736ed in 0.4388s, epoch ETA: 0.4388s\t\n",
      "Epoch: 218 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.302 \t auc: 0.863 \t r2: 0.327 \n",
      "\n",
      "Running epoch 219...\n",
      "Total epoch time: 75.4506151676178ted in 0.4482s, epoch ETA: 0.4482s\t\n",
      "Epoch: 219 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.302 \t auc: 0.864 \t r2: 0.328 \n",
      "\n",
      "Running epoch 220...\n",
      "Total epoch time: 75.17981171607971ed in 0.4386s, epoch ETA: 0.4386s\t\n",
      "Epoch: 220 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.492 \t rmse: 0.302 \t auc: 0.864 \t r2: 0.328 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.10526967048645ed in 0.3591s, epoch ETA: 0.1796s\t\n",
      "Epoch: 220 Test Metrics:\n",
      " acc: 0.850 \t log loss: 0.367 \t f1: 0.408 \t rmse: 0.336 \t auc: 0.805 \t r2: 0.226\n",
      "**********\n",
      "Running epoch 221...\n",
      "Total epoch time: 75.43565154075623ed in 0.4329s, epoch ETA: 0.4329s\t\n",
      "Epoch: 221 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.494 \t rmse: 0.302 \t auc: 0.864 \t r2: 0.329 \n",
      "\n",
      "Running epoch 222...\n",
      "Total epoch time: 75.07916784286499ed in 0.4469s, epoch ETA: 0.4469s\t\n",
      "Epoch: 222 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.493 \t rmse: 0.302 \t auc: 0.864 \t r2: 0.328 \n",
      "\n",
      "Running epoch 223...\n",
      "Total epoch time: 75.29067587852478ed in 0.4301s, epoch ETA: 0.4301s\t\n",
      "Epoch: 223 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.493 \t rmse: 0.302 \t auc: 0.864 \t r2: 0.328 \n",
      "\n",
      "Running epoch 224...\n",
      "Total epoch time: 75.27489399909973ed in 0.4481s, epoch ETA: 0.4481s\t\n",
      "Epoch: 224 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.495 \t rmse: 0.302 \t auc: 0.865 \t r2: 0.330 \n",
      "\n",
      "Running epoch 225...\n",
      "Total epoch time: 75.53058743476868ed in 0.4484s, epoch ETA: 0.4484s\t\n",
      "Epoch: 225 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.495 \t rmse: 0.302 \t auc: 0.865 \t r2: 0.330 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.13616728782654ed in 0.3461s, epoch ETA: 0.1731s\t\n",
      "Epoch: 225 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.368 \t f1: 0.402 \t rmse: 0.336 \t auc: 0.804 \t r2: 0.225\n",
      "**********\n",
      "Running epoch 226...\n",
      "Total epoch time: 75.62316584587097ed in 0.4426s, epoch ETA: 0.4426s\t\n",
      "Epoch: 226 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.498 \t rmse: 0.302 \t auc: 0.865 \t r2: 0.331 \n",
      "\n",
      "Running epoch 227...\n",
      "Total epoch time: 75.26364850997925ed in 0.4407s, epoch ETA: 0.4407s\t\n",
      "Epoch: 227 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.495 \t rmse: 0.302 \t auc: 0.865 \t r2: 0.330 \n",
      "\n",
      "Running epoch 228...\n",
      "Total epoch time: 75.15882182121277ed in 0.4349s, epoch ETA: 0.4349s\t\n",
      "Epoch: 228 Train Metrics:\n",
      " acc: 0.877 log loss: nan \t f1: 0.494 \t rmse: 0.302 \t auc: 0.865 \t r2: 0.329 \n",
      "\n",
      "Running epoch 229...\n",
      "Total epoch time: 75.3481695652008ted in 0.4483s, epoch ETA: 0.4483s\t\n",
      "Epoch: 229 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.496 \t rmse: 0.302 \t auc: 0.865 \t r2: 0.331 \n",
      "\n",
      "Running epoch 230...\n",
      "Total epoch time: 75.05231547355652ed in 0.4376s, epoch ETA: 0.4376s\t\n",
      "Epoch: 230 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.496 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.332 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.32247519493103ed in 0.3445s, epoch ETA: 0.1722s\t\n",
      "Epoch: 230 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.367 \t f1: 0.411 \t rmse: 0.336 \t auc: 0.805 \t r2: 0.224\n",
      "**********\n",
      "Running epoch 231...\n",
      "Total epoch time: 75.27175045013428ed in 0.4313s, epoch ETA: 0.4313s\t\n",
      "Epoch: 231 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.499 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.332 \n",
      "\n",
      "Running epoch 232...\n",
      "Total epoch time: 75.24065375328064ed in 0.4395s, epoch ETA: 0.4395s\t\n",
      "Epoch: 232 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.499 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.332 \n",
      "\n",
      "Running epoch 233...\n",
      "Total epoch time: 75.14788842201233ed in 0.433s, epoch ETA: 0.433s\ts\t\n",
      "Epoch: 233 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.498 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.333 \n",
      "\n",
      "Running epoch 234...\n",
      "Total epoch time: 75.28143811225891ed in 0.4418s, epoch ETA: 0.4418s\t\n",
      "Epoch: 234 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.498 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.333 \n",
      "\n",
      "Running epoch 235...\n",
      "Total epoch time: 75.30161619186401ed in 0.4398s, epoch ETA: 0.4398s\t\n",
      "Epoch: 235 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.499 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.332 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 48.147268533706665d in 0.3463s, epoch ETA: 0.1731s\t\n",
      "Epoch: 235 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.369 \t f1: 0.403 \t rmse: 0.336 \t auc: 0.803 \t r2: 0.222\n",
      "**********\n",
      "Running epoch 236...\n",
      "Total epoch time: 74.77028703689575ed in 0.4259s, epoch ETA: 0.4259s\t\n",
      "Epoch: 236 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.498 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.334 \n",
      "\n",
      "Running epoch 237...\n",
      "Total epoch time: 75.45186066627502ed in 0.4487s, epoch ETA: 0.4487s\t\n",
      "Epoch: 237 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.498 \t rmse: 0.301 \t auc: 0.865 \t r2: 0.332 \n",
      "\n",
      "Running epoch 238...\n",
      "Total epoch time: 75.37628173828125ed in 0.4431s, epoch ETA: 0.4431s\t\n",
      "Epoch: 238 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.499 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.332 \n",
      "\n",
      "Running epoch 239...\n",
      "Total epoch time: 75.46387887001038ed in 0.4359s, epoch ETA: 0.4359s\t\n",
      "Epoch: 239 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.500 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Running epoch 240...\n",
      "Total epoch time: 75.2010669708252ted in 0.4122s, epoch ETA: 0.4122s\t\n",
      "Epoch: 240 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.498 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.332 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.29842805862427ed in 0.3462s, epoch ETA: 0.1731s\t\n",
      "Epoch: 240 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.370 \t f1: 0.395 \t rmse: 0.337 \t auc: 0.802 \t r2: 0.221\n",
      "**********\n",
      "Running epoch 241...\n",
      "Total epoch time: 75.3107500076294ted in 0.4203s, epoch ETA: 0.4203s\t\n",
      "Epoch: 241 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.501 \t rmse: 0.301 \t auc: 0.866 \t r2: 0.334 \n",
      "\n",
      "Running epoch 242...\n",
      "Total epoch time: 76.05761909484863ed in 0.4191s, epoch ETA: 0.4191s\t\n",
      "Epoch: 242 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.500 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Running epoch 243...\n",
      "Total epoch time: 76.04680514335632ed in 0.4518s, epoch ETA: 0.4518s\t\n",
      "Epoch: 243 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.500 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Running epoch 244...\n",
      "Total epoch time: 76.63846325874329ed in 0.4446s, epoch ETA: 0.4446s\t\n",
      "Epoch: 244 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.503 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.336 \n",
      "\n",
      "Running epoch 245...\n",
      "Total epoch time: 76.78924083709717ed in 0.4302s, epoch ETA: 0.4302s\t\n",
      "Epoch: 245 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.501 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 49.6349458694458ted in 0.361s, epoch ETA: 0.1805s\t\t\n",
      "Epoch: 245 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.370 \t f1: 0.405 \t rmse: 0.337 \t auc: 0.802 \t r2: 0.221\n",
      "**********\n",
      "Running epoch 246...\n",
      "Total epoch time: 76.47175979614258ed in 0.4438s, epoch ETA: 0.4439s\t\n",
      "Epoch: 246 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.502 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Running epoch 247...\n",
      "Total epoch time: 76.91396641731262ed in 0.4494s, epoch ETA: 0.4494s\t\n",
      "Epoch: 247 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.501 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Running epoch 248...\n",
      "Total epoch time: 76.86737132072449ed in 0.4509s, epoch ETA: 0.4509s\t\n",
      "Epoch: 248 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.500 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.334 \n",
      "\n",
      "Running epoch 249...\n",
      "Total epoch time: 76.51562452316284ed in 0.4408s, epoch ETA: 0.4408s\t\n",
      "Epoch: 249 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.501 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Running epoch 250...\n",
      "Total epoch time: 75.82908368110657ed in 0.4472s, epoch ETA: 0.4472s\t\n",
      "Epoch: 250 Train Metrics:\n",
      " acc: 0.878 log loss: nan \t f1: 0.501 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.335 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 49.014256954193115d in 0.3552s, epoch ETA: 0.1776s\t\n",
      "Epoch: 250 Test Metrics:\n",
      " acc: 0.849 \t log loss: nan \t f1: 0.409 \t rmse: 0.336 \t auc: 0.803 \t r2: 0.221\n",
      "**********\n",
      "Running epoch 251...\n",
      "Total epoch time: 76.17785215377808ed in 0.4447s, epoch ETA: 0.4447s\t\n",
      "Epoch: 251 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.504 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.337 \n",
      "\n",
      "Running epoch 252...\n",
      "Total epoch time: 76.8144702911377ted in 0.4461s, epoch ETA: 0.4461s\t\n",
      "Epoch: 252 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.504 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.337 \n",
      "\n",
      "Running epoch 253...\n",
      "Total epoch time: 76.99803447723389ed in 0.4447s, epoch ETA: 0.4447s\t\n",
      "Epoch: 253 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.504 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.337 \n",
      "\n",
      "Running epoch 254...\n",
      "Total epoch time: 76.52682733535767ed in 0.4479s, epoch ETA: 0.4479s\t\n",
      "Epoch: 254 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.502 \t rmse: 0.301 \t auc: 0.867 \t r2: 0.336 \n",
      "\n",
      "Running epoch 255...\n",
      "Total epoch time: 76.5220398902893ted in 0.4437s, epoch ETA: 0.4437s\t\n",
      "Epoch: 255 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.504 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.338 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 49.91996932029724ed in 0.3405s, epoch ETA: 0.1703s\t\n",
      "Epoch: 255 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.370 \t f1: 0.401 \t rmse: 0.337 \t auc: 0.803 \t r2: 0.221\n",
      "**********\n",
      "Running epoch 256...\n",
      "Total epoch time: 76.6600284576416ted in 0.4353s, epoch ETA: 0.4353s\t\n",
      "Epoch: 256 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.506 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.338 \n",
      "\n",
      "Running epoch 257...\n",
      "Total epoch time: 76.83196115493774ed in 0.4514s, epoch ETA: 0.4514s\t\n",
      "Epoch: 257 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.504 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.338 \n",
      "\n",
      "Running epoch 258...\n",
      "Total epoch time: 76.49904894828796ed in 0.446s, epoch ETA: 0.446s\ts\t\n",
      "Epoch: 258 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.506 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.338 \n",
      "\n",
      "Running epoch 259...\n",
      "Total epoch time: 76.71951818466187ed in 0.4454s, epoch ETA: 0.4454s\t\n",
      "Epoch: 259 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.338 \n",
      "\n",
      "Running epoch 260...\n",
      "Total epoch time: 76.64893221855164ed in 0.4379s, epoch ETA: 0.4379s\t\n",
      "Epoch: 260 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.506 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.339 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 49.94666242599487ed in 0.3607s, epoch ETA: 0.1804s\t\n",
      "Epoch: 260 Test Metrics:\n",
      " acc: 0.849 \t log loss: 0.370 \t f1: 0.405 \t rmse: 0.337 \t auc: 0.802 \t r2: 0.220\n",
      "**********\n",
      "Running epoch 261...\n",
      "Total epoch time: 76.60954856872559ed in 0.4399s, epoch ETA: 0.4399s\t\n",
      "Epoch: 261 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.337 \n",
      "\n",
      "Running epoch 262...\n",
      "Total epoch time: 76.9642653465271ted in 0.4457s, epoch ETA: 0.4457s\t\n",
      "Epoch: 262 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.506 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 263...\n",
      "Total epoch time: 76.62313985824585ed in 0.4384s, epoch ETA: 0.4384s\t\n",
      "Epoch: 263 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.339 \n",
      "\n",
      "Running epoch 264...\n",
      "Total epoch time: 76.80640530586243ed in 0.4342s, epoch ETA: 0.4342s\t\n",
      "Epoch: 264 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.508 \t rmse: 0.299 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 265...\n",
      "Total epoch time: 76.91031169891357ed in 0.4475s, epoch ETA: 0.4475s\t\n",
      "Epoch: 265 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.341 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 49.82531023025513ed in 0.3619s, epoch ETA: 0.181s\t\t\n",
      "Epoch: 265 Test Metrics:\n",
      " acc: 0.849 \t log loss: nan \t f1: 0.408 \t rmse: 0.337 \t auc: 0.802 \t r2: 0.219\n",
      "**********\n",
      "Running epoch 266...\n",
      "Total epoch time: 76.71230435371399ed in 0.4388s, epoch ETA: 0.4388s\t\n",
      "Epoch: 266 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.339 \n",
      "\n",
      "Running epoch 267...\n",
      "Total epoch time: 76.70826435089111ed in 0.4475s, epoch ETA: 0.4475s\t\n",
      "Epoch: 267 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 268...\n",
      "Total epoch time: 76.79664063453674ed in 0.4504s, epoch ETA: 0.4504s\t\n",
      "Epoch: 268 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.299 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 269...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch time: 76.70652985572815ed in 0.4447s, epoch ETA: 0.4447s\t\n",
      "Epoch: 269 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.508 \t rmse: 0.299 \t auc: 0.869 \t r2: 0.341 \n",
      "\n",
      "Running epoch 270...\n",
      "Total epoch time: 76.04609370231628ed in 0.4245s, epoch ETA: 0.4245s\t\n",
      "Epoch: 270 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.506 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.854592084884644d in 0.3617s, epoch ETA: 0.1809s\t\n",
      "Epoch: 270 Test Metrics:\n",
      " acc: 0.848 \t log loss: nan \t f1: 0.407 \t rmse: 0.337 \t auc: 0.801 \t r2: 0.217\n",
      "**********\n",
      "Running epoch 271...\n",
      "Total epoch time: 76.01705241203308ed in 0.4292s, epoch ETA: 0.4293s\t\n",
      "Epoch: 271 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.338 \n",
      "\n",
      "Running epoch 272...\n",
      "Total epoch time: 75.8475387096405ted in 0.424s, epoch ETA: 0.424s\ts\t\n",
      "Epoch: 272 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.508 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 273...\n",
      "Total epoch time: 75.6196517944336ted in 0.4508s, epoch ETA: 0.4508s\t\n",
      "Epoch: 273 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.508 \t rmse: 0.299 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 274...\n",
      "Total epoch time: 75.83565902709961ed in 0.4495s, epoch ETA: 0.4495s\t\n",
      "Epoch: 274 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.339 \n",
      "\n",
      "Running epoch 275...\n",
      "Total epoch time: 75.78182005882263ed in 0.4401s, epoch ETA: 0.4401s\t\n",
      "Epoch: 275 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.339 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.83077883720398ed in 0.3544s, epoch ETA: 0.1772s\t\n",
      "Epoch: 275 Test Metrics:\n",
      " acc: 0.849 \t log loss: nan \t f1: 0.389 \t rmse: 0.337 \t auc: 0.802 \t r2: 0.217\n",
      "**********\n",
      "Running epoch 276...\n",
      "Total epoch time: 75.62934803962708ed in 0.4384s, epoch ETA: 0.4384s\t\n",
      "Epoch: 276 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.337 \n",
      "\n",
      "Running epoch 277...\n",
      "Total epoch time: 76.08609938621521ed in 0.4408s, epoch ETA: 0.4408s\t\n",
      "Epoch: 277 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 278...\n",
      "Total epoch time: 76.12986755371094ed in 0.4459s, epoch ETA: 0.4459s\t\n",
      "Epoch: 278 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.505 \t rmse: 0.300 \t auc: 0.868 \t r2: 0.338 \n",
      "\n",
      "Running epoch 279...\n",
      "Total epoch time: 75.9144377708435ted in 0.438s, epoch ETA: 0.438s\ts\t\n",
      "Epoch: 279 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 280...\n",
      "Total epoch time: 75.75005626678467ed in 0.4484s, epoch ETA: 0.4484s\t\n",
      "Epoch: 280 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.509 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.342 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.78912281990051ed in 0.3436s, epoch ETA: 0.1718s\t\n",
      "Epoch: 280 Test Metrics:\n",
      " acc: 0.849 \t log loss: nan \t f1: 0.408 \t rmse: 0.337 \t auc: 0.803 \t r2: 0.218\n",
      "**********\n",
      "Running epoch 281...\n",
      "Total epoch time: 75.79480504989624ed in 0.4448s, epoch ETA: 0.4448s\t\n",
      "Epoch: 281 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.339 \n",
      "\n",
      "Running epoch 282...\n",
      "Total epoch time: 76.01310300827026ed in 0.4329s, epoch ETA: 0.4329s\t\n",
      "Epoch: 282 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.508 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.341 \n",
      "\n",
      "Running epoch 283...\n",
      "Total epoch time: 75.93487024307251ed in 0.4394s, epoch ETA: 0.4394s\t\n",
      "Epoch: 283 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.299 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 284...\n",
      "Total epoch time: 75.81291556358337ed in 0.4495s, epoch ETA: 0.4495s\t\n",
      "Epoch: 284 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.507 \t rmse: 0.300 \t auc: 0.869 \t r2: 0.340 \n",
      "\n",
      "Running epoch 285...\n",
      "Total epoch time: 76.06438732147217ed in 0.4292s, epoch ETA: 0.4292s\t\n",
      "Epoch: 285 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.509 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.342 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.97831606864929ed in 0.3491s, epoch ETA: 0.1746s\t\n",
      "Epoch: 285 Test Metrics:\n",
      " acc: 0.849 \t log loss: nan \t f1: 0.403 \t rmse: 0.337 \t auc: 0.803 \t r2: 0.219\n",
      "**********\n",
      "Running epoch 286...\n",
      "Total epoch time: 76.18048286437988ed in 0.4445s, epoch ETA: 0.4445s\t\n",
      "Epoch: 286 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.510 \t rmse: 0.299 \t auc: 0.871 \t r2: 0.343 \n",
      "\n",
      "Running epoch 287...\n",
      "Total epoch time: 75.78449964523315ed in 0.4395s, epoch ETA: 0.4395s\t\n",
      "Epoch: 287 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.510 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.343 \n",
      "\n",
      "Running epoch 288...\n",
      "Total epoch time: 75.3060073852539ted in 0.4102s, epoch ETA: 0.4102s\t\n",
      "Epoch: 288 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.509 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.341 \n",
      "\n",
      "Running epoch 289...\n",
      "Total epoch time: 75.39351439476013ed in 0.4379s, epoch ETA: 0.4379s\t\n",
      "Epoch: 289 Train Metrics:\n",
      " acc: 0.879 log loss: nan \t f1: 0.509 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.342 \n",
      "\n",
      "Running epoch 290...\n",
      "Total epoch time: 75.21292304992676ed in 0.4338s, epoch ETA: 0.4338s\t\n",
      "Epoch: 290 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.509 \t rmse: 0.299 \t auc: 0.871 \t r2: 0.344 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.704869508743286d in 0.36s, epoch ETA: 0.18s\t14s\t\n",
      "Epoch: 290 Test Metrics:\n",
      " acc: 0.849 \t log loss: nan \t f1: 0.402 \t rmse: 0.337 \t auc: 0.803 \t r2: 0.220\n",
      "**********\n",
      "Running epoch 291...\n",
      "Total epoch time: 74.97602581977844ed in 0.4253s, epoch ETA: 0.4253s\t\n",
      "Epoch: 291 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.510 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.342 \n",
      "\n",
      "Running epoch 292...\n",
      "Total epoch time: 75.35474920272827ed in 0.4359s, epoch ETA: 0.4359s\t\n",
      "Epoch: 292 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.510 \t rmse: 0.299 \t auc: 0.870 \t r2: 0.343 \n",
      "\n",
      "Running epoch 293...\n",
      "Total epoch time: 75.80241060256958ed in 0.447s, epoch ETA: 0.447s\ts\t\n",
      "Epoch: 293 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.509 \t rmse: 0.299 \t auc: 0.871 \t r2: 0.343 \n",
      "\n",
      "Running epoch 294...\n",
      "Total epoch time: 75.3566505908966ted in 0.4191s, epoch ETA: 0.4191s\t\n",
      "Epoch: 294 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.511 \t rmse: 0.299 \t auc: 0.871 \t r2: 0.344 \n",
      "\n",
      "Running epoch 295...\n",
      "Total epoch time: 75.15074467658997ed in 0.4165s, epoch ETA: 0.4165s\t\n",
      "Epoch: 295 Train Metrics:\n",
      " acc: 0.880 log loss: nan \t f1: 0.512 \t rmse: 0.299 \t auc: 0.871 \t r2: 0.344 \n",
      "\n",
      "Save variables to disk\n",
      "**********\n",
      "Start to test model....\n",
      "Total epoch time: 48.04858636856079ed in 0.3531s, epoch ETA: 0.1766s\t\n",
      "Epoch: 295 Test Metrics:\n",
      " acc: 0.849 \t log loss: nan \t f1: 0.400 \t rmse: 0.337 \t auc: 0.803 \t r2: 0.220\n",
      "**********\n",
      "Running epoch 296...\n",
      "Batch 1310 to 1320 (0.79%) completed in 0.4412s, epoch ETA: 15.44s\t\t\r"
     ]
    }
   ],
   "source": [
    "# The code is rewritten based on source code from tensorflow tutorial for Recurrent Neural Network.\n",
    "# https://www.tensorflow.org/versions/0.6.0/tutorials/recurrent/index.html\n",
    "# You can get source code for the tutorial from\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py\n",
    "#\n",
    "# There is dropout on each hidden layer to prevent the model from overfitting\n",
    "#\n",
    "# Here is an useful practical guide for training dropout networks\n",
    "# https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "# You can find the practical guide on Appendix A\n",
    "\n",
    "\n",
    "def add_gradient_noise(t, stddev=1e-3, name=None):\n",
    "    \"\"\"\n",
    "    Adds gradient noise as described in http://arxiv.org/abs/1511.06807 [2].\n",
    "\n",
    "    The input Tensor `t` should be a gradient.\n",
    "\n",
    "    The output will be `t` + gaussian noise.\n",
    "\n",
    "    0.001 was said to be a good fixed value for memory networks [2].\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"add_gradient_noise\", [t, stddev]) as name:\n",
    "        t = tf.convert_to_tensor(t, name=\"t\")\n",
    "        gn = tf.random_normal(tf.shape(t), stddev=stddev)\n",
    "        return tf.add(t, gn, name=name)\n",
    "\n",
    "\n",
    "class StudentModel(object):\n",
    "    def __init__(self, is_training, config):\n",
    "        self._batch_size = batch_size = FLAGS.batch_size\n",
    "        self.num_skills = num_skills = config.num_skills\n",
    "        self.hidden_size = size = FLAGS.hidden_size\n",
    "        self.num_steps = num_steps = config.num_steps\n",
    "        input_size = num_skills * 2\n",
    "\n",
    "        inputs = self._input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "        self._target_id = target_id = tf.placeholder(tf.int32, [None])\n",
    "        self._target_correctness = target_correctness = tf.placeholder(tf.float32, [None])\n",
    "        final_hidden_size = size\n",
    "        hidden_layers = []\n",
    "        for i in range(FLAGS.hidden_layer_num):\n",
    "            final_hidden_size = size / (i + 1)\n",
    "            hidden1 = tf.nn.rnn_cell.LSTMCell(final_hidden_size, state_is_tuple=True)\n",
    "            if is_training and config.keep_prob < 1:\n",
    "                hidden1 = tf.nn.rnn_cell.DropoutWrapper(hidden1, output_keep_prob=FLAGS.keep_prob)\n",
    "            hidden_layers.append(hidden1)\n",
    "\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(hidden_layers, state_is_tuple=True)\n",
    "\n",
    "        input_data = tf.reshape(self._input_data, [-1])\n",
    "        # one-hot encoding\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            labels = tf.expand_dims(input_data, 1)\n",
    "            indices = tf.expand_dims(tf.range(0, batch_size * num_steps, 1), 1)\n",
    "            concatenated = tf.concat([indices, labels], 1)\n",
    "            inputs = tf.sparse_to_dense(concatenated, tf.stack([batch_size * num_steps, input_size]), 1.0, 0.0)\n",
    "            inputs.set_shape([batch_size * num_steps, input_size])\n",
    "\n",
    "        # [batch_size, num_steps, input_size]\n",
    "        inputs = tf.reshape(inputs, [-1, num_steps, input_size])\n",
    "        x = tf.transpose(inputs, [1, 0, 2])\n",
    "        # Reshape to (n_steps*batch_size, n_input)\n",
    "        x = tf.reshape(x, [-1, input_size])\n",
    "        # Split to get a list of 'n_steps'\n",
    "        # tensors of shape (doc_num, n_input)\n",
    "        x = tf.split(x, num_steps, 0)\n",
    "        # inputs = [tf.squeeze(input_, [1]) for input_ in tf.split(1, num_steps, inputs)]\n",
    "        # outputs, state = tf.nn.rnn(hidden1, x, dtype=tf.float32)\n",
    "        outputs, state = tf.contrib.rnn.static_rnn(cell, x, dtype=tf.float32)\n",
    "        output = tf.reshape(tensor=tf.concat(outputs, 1), shape=[-1, tf.cast(final_hidden_size, dtype=tf.int32)])\n",
    "        # calculate the logits from last hidden layer to output layer\n",
    "        sigmoid_w = tf.get_variable(\"sigmoid_w\", [final_hidden_size, num_skills])\n",
    "        sigmoid_b = tf.get_variable(\"sigmoid_b\", [num_skills])\n",
    "        logits = tf.matmul(output, sigmoid_w) + sigmoid_b\n",
    "\n",
    "        # from output nodes to pick up the right one we want\n",
    "        logits = tf.reshape(logits, [-1])\n",
    "        selected_logits = tf.gather(logits, self.target_id)\n",
    "        self._all_logits = logits\n",
    "\n",
    "        # make prediction\n",
    "        self._pred = tf.sigmoid(selected_logits)\n",
    "\n",
    "        # loss function\n",
    "        loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=selected_logits, labels=target_correctness))\n",
    "\n",
    "        # self._cost = cost = tf.reduce_mean(loss)\n",
    "        self._cost = cost = loss\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @property\n",
    "    def input_data(self):\n",
    "        return self._input_data\n",
    "\n",
    "    @property\n",
    "    def auc(self):\n",
    "        return self._auc\n",
    "\n",
    "    @property\n",
    "    def pred(self):\n",
    "        return self._pred\n",
    "\n",
    "    @property\n",
    "    def target_id(self):\n",
    "        return self._target_id\n",
    "\n",
    "    @property\n",
    "    def target_correctness(self):\n",
    "        return self._target_correctness\n",
    "\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self._initial_state\n",
    "\n",
    "    @property\n",
    "    def all_logits(self):\n",
    "        return self._all_logits\n",
    "\n",
    "    @property\n",
    "    def cost(self):\n",
    "        return self._cost\n",
    "\n",
    "    @property\n",
    "    def final_state(self):\n",
    "        return self._final_state\n",
    "\n",
    "\n",
    "class HyperParamsConfig(object):\n",
    "    \"\"\"Small config.\"\"\"\n",
    "    init_scale = 0.05\n",
    "    num_steps = 0\n",
    "    max_grad_norm = FLAGS.max_grad_norm\n",
    "    max_max_epoch = FLAGS.epochs\n",
    "    keep_prob = FLAGS.keep_prob\n",
    "    num_skills = 0\n",
    "\n",
    "\n",
    "def run_epoch(session, m, students, eval_op, verbose=False):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    index = 0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    all_all_logits = []\n",
    "    while index + m.batch_size < len(students):\n",
    "        batch_start_time = time.time()\n",
    "        x = np.zeros((m.batch_size, m.num_steps))\n",
    "        target_id = []\n",
    "        target_correctness = []\n",
    "        count = 0\n",
    "        for i in range(m.batch_size):\n",
    "            student = students[index + i]\n",
    "            problem_ids = student[1]\n",
    "            correctness = student[2]\n",
    "            for j in range(len(problem_ids) - 1):\n",
    "                problem_id = int(problem_ids[j])\n",
    "                label_index = 0\n",
    "                if int(correctness[j]) == 0:\n",
    "                    label_index = problem_id\n",
    "                else:\n",
    "                    label_index = problem_id + m.num_skills\n",
    "                x[i, j] = label_index\n",
    "                target_id.append(i * m.num_steps * m.num_skills + j * m.num_skills + int(problem_ids[j + 1]))\n",
    "                target_correctness.append(int(correctness[j + 1]))\n",
    "                actual_labels.append(int(correctness[j + 1]))\n",
    "\n",
    "        index += m.batch_size\n",
    "\n",
    "        pred, _, all_logits = session.run([m.pred, eval_op, m.all_logits], feed_dict={\n",
    "            m.input_data: x, m.target_id: target_id,\n",
    "            m.target_correctness: target_correctness})\n",
    "\n",
    "        for p in pred:\n",
    "            pred_labels.append(p)\n",
    "\n",
    "        all_all_logits.append(all_logits)\n",
    "\n",
    "        eta = ('Batch {} to {} ({:.3}%) completed in {:.4}s, epoch ETA: {:.4}s\\t'\n",
    "               .format(index - m.batch_size, index, index / len(students), time.time() - batch_start_time,\n",
    "                       (time.time() - batch_start_time) * ((len(students) - index) / m.batch_size)))\n",
    "        print('{}\\r'.format(eta), end='', flush=True)\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(actual_labels, pred_labels))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(actual_labels, pred_labels, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    # calculate r^2\n",
    "    r2 = r2_score(actual_labels, pred_labels)\n",
    "    f1 = f1_score(actual_labels, np.round(pred_labels))\n",
    "    lloss = log_loss(actual_labels, pred_labels)\n",
    "    acc = accuracy_score(actual_labels, np.round(pred_labels))\n",
    "    print('\\rTotal epoch time:', time.time() - epoch_start_time)\n",
    "    return acc, lloss, f1, rmse, auc, r2, np.concatenate(all_all_logits)\n",
    "\n",
    "\n",
    "def read_data_from_csv_file(fileName, shuffle=False):\n",
    "    config = HyperParamsConfig()\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    rows = []\n",
    "    max_skill_num = 0\n",
    "    max_num_problems = 0\n",
    "    with open(fileName, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "    index = 0\n",
    "    i = 0\n",
    "    print(\"the number of rows is \" + str(len(rows)))\n",
    "    tuple_rows = []\n",
    "    # turn list to tuple\n",
    "    while (index < len(rows) - 1):\n",
    "        problems_num = int(rows[index][0])\n",
    "        tmp_max_skill = max(map(int, rows[index + 1]))\n",
    "        if (tmp_max_skill > max_skill_num):\n",
    "            max_skill_num = tmp_max_skill\n",
    "        if (problems_num <= 2):\n",
    "            index += 3\n",
    "        else:\n",
    "            if problems_num > max_num_problems:\n",
    "                max_num_problems = problems_num\n",
    "            tup = (rows[index], rows[index + 1], rows[index + 2])\n",
    "            tuple_rows.append(tup)\n",
    "            index += 3\n",
    "    # shuffle the tuple\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(tuple_rows)\n",
    "    print(\"The number of students is \", len(tuple_rows))\n",
    "    print(\"Finish reading data\")\n",
    "    return tuple_rows, max_num_problems, max_skill_num + 1\n",
    "\n",
    "\n",
    "def main(unused_args):\n",
    "    start_time = time.time()\n",
    "    config = HyperParamsConfig()\n",
    "    eval_config = HyperParamsConfig()\n",
    "    timestamp = str(time.time())\n",
    "    train_data_path = FLAGS.train_data_path\n",
    "    # path to your test data set\n",
    "    test_data_path = FLAGS.test_data_path\n",
    "    # the file to store your test results\n",
    "    result_file_path = \"run_logs_{}\".format(timestamp)\n",
    "    # your model name\n",
    "    model_name = \"DKT\"\n",
    "\n",
    "    train_students, train_max_num_problems, train_max_skill_num = read_data_from_csv_file(train_data_path, shuffle=True)\n",
    "    config.num_steps = train_max_num_problems\n",
    "    print('train_max_num_problems=%d, train_max_skill_num=%d' % (train_max_num_problems, train_max_skill_num))\n",
    "\n",
    "    test_students, test_max_num_problems, test_max_skill_num = read_data_from_csv_file(test_data_path, shuffle=False)\n",
    "    config.num_skills = max(test_max_skill_num, train_max_skill_num)\n",
    "    eval_config.num_steps = test_max_num_problems\n",
    "    eval_config.num_skills = max(test_max_skill_num, train_max_skill_num)\n",
    "    print('test_max_num_problems=%d, test_max_skill_num=%d' % (test_max_num_problems, test_max_skill_num))\n",
    "    print('Reading time', round(time.time() - start_time, 3), 's')\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "                                      log_device_placement=FLAGS.log_device_placement)\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        # decay learning rate\n",
    "        starter_learning_rate = FLAGS.learning_rate\n",
    "        learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 3000, 0.96, staircase=True)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=FLAGS.epsilon)\n",
    "        print('Time checkpoint', round(time.time() - start_time, 4), 's')\n",
    "        print('Starting tf session...')\n",
    "        with tf.Session(config=session_conf) as session:\n",
    "\n",
    "            initializer = tf.random_uniform_initializer(-config.init_scale, config.init_scale)\n",
    "            # training model\n",
    "            with tf.variable_scope(\"model\", reuse=None, initializer=initializer):\n",
    "                m = StudentModel(is_training=True, config=config)\n",
    "            # testing model\n",
    "            with tf.variable_scope(\"model\", reuse=True, initializer=initializer):\n",
    "                mtest = StudentModel(is_training=False, config=eval_config)\n",
    "\n",
    "            grads_and_vars = optimizer.compute_gradients(m.cost)\n",
    "            grads_and_vars = [(tf.clip_by_norm(g, FLAGS.max_grad_norm), v)\n",
    "                              for g, v in grads_and_vars if g is not None]\n",
    "            grads_and_vars = [(add_gradient_noise(g), v) for g, v in grads_and_vars]\n",
    "            train_op = optimizer.apply_gradients(grads_and_vars, name=\"train_op\", global_step=global_step)\n",
    "            print('Time checkpoint', round((time.time() - start_time) / 60, 4), 'min')\n",
    "            print('Running session...')\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            # log hyperparameters to results file\n",
    "            with open(result_file_path, \"a+\") as f:\n",
    "                print(\"Writing hyperparameters into file\")\n",
    "                f.write(\"Hidden layer size: %d \\n\" % (FLAGS.hidden_size))\n",
    "                f.write(\"Dropout rate: %.3f \\n\" % (FLAGS.keep_prob))\n",
    "                f.write(\"Batch size: %d \\n\" % (FLAGS.batch_size))\n",
    "                f.write(\"Max grad norm: %d \\n\" % (FLAGS.max_grad_norm))\n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            print('Starting epochs...')\n",
    "            print('Time checkpoint', round((time.time() - start_time) / 60, 4), 'min')\n",
    "            for i in range(config.max_max_epoch):\n",
    "                print('Running epoch {}...\\r'.format(i + 1))\n",
    "                acc, lloss, f1, rmse, auc, r2, _ = run_epoch(session, m, train_students, train_op, verbose=False)\n",
    "                print(\"Epoch: %d Train Metrics:\\n acc: %.3f log loss: %.3f \\t f1: %.3f \\t rmse: %.3f \\t auc: %.3f \\t r2: %.3f \\n\" \n",
    "                      % (i + 1, acc, lloss, f1, rmse, auc, r2))\n",
    "\n",
    "                if (i + 1) % FLAGS.evaluation_interval == 0:\n",
    "                    print(\"Save variables to disk\")\n",
    "                    save_path = saver.save(session, './' + model_name)\n",
    "                    print(\"*\" * 10)\n",
    "                    print(\"Start to test model....\")\n",
    "                    acc, lloss, f1, rmse, auc, r2, all_logits = run_epoch(session, mtest, test_students, tf.no_op(), verbose=True)\n",
    "                    print(\"Epoch: %d Test Metrics:\\n acc: %.3f \\t log loss: %.3f \\t f1: %.3f \\t rmse: %.3f \\t auc: %.3f \\t r2: %.3f\" \n",
    "                          % (i + 1, acc, lloss, f1, rmse, auc, r2))\n",
    "                    with open(result_file_path, \"a+\") as f:\n",
    "                        f.write(\"Epoch: %d Test Metrics:\\n rmse: %.3f \\t auc: %.3f \\t r2: %.3f\" % (\n",
    "                            (i + 1) / 2, rmse, auc, r2))\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "                        print(\"*\" * 10)\n",
    "                    # save the logits\n",
    "                    if FLAGS.save_test_logits:\n",
    "                        np.savetxt(result_file_path + ('.e%02d.logits' % (i + 1)), all_logits)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
