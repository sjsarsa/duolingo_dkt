{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 285973 instances across 100000 exercises...\n",
      "Loaded 567856 instances across 200000 exercises...\n",
      "Loaded 850511 instances across 300000 exercises...\n",
      "sentences: 5198\n",
      "number of exercises:  326792\n",
      "instances: 19795\n",
      "total instances: 926657\n",
      "words: 2178\n",
      "max word count 47130\n",
      "reduced instances: 1630\n",
      "n users 1213\n",
      "max n exercises by user 7676\n",
      "min n exercises by user 64\n",
      "formats: 3\n",
      "sessions: 3\n",
      "{'format:reverse_tap', 'format:reverse_translate', 'format:listen'}\n",
      "{'session:practice', 'session:test', 'session:lesson'}\n",
      "\n",
      "\n",
      "With test set:\n",
      "sentences: 5686\n",
      "number of exercises:  370402\n",
      "instances: 30409\n",
      "total instances: 1064228\n",
      "words: 2301\n",
      "max word count 55197\n",
      "max word length 15\n",
      "reduced instances: 2306\n",
      "n test users 1206\n",
      "max n exercises by test user 310\n",
      "min n exercises by test user 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "filename = 'fr_en.slam.20171218.train'\n",
    "\n",
    "sentences = set()\n",
    "duolingo_exercises = set()\n",
    "reduced_instances = set()\n",
    "instances = set()\n",
    "users = defaultdict(int)\n",
    "test_users = defaultdict(int)\n",
    "formats = set()\n",
    "sessions = set()\n",
    "num_words = 0\n",
    "num_exercises = 0\n",
    "num_instances = 0\n",
    "word_counts = defaultdict(int)\n",
    "max_word_len = 0\n",
    "\n",
    "sentence = ''\n",
    "exercise_type = ''\n",
    "with open(filename, 'rt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "\n",
    "        # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "        if len(line) == 0:\n",
    "            sentences.add(sentence)\n",
    "            num_exercises += 1\n",
    "            if num_exercises % 100000 == 0:\n",
    "                print('Loaded ' + str(num_instances) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "\n",
    "        # If the line starts with #, then we're beginning a new exercise\n",
    "        elif line[0] == '#':\n",
    "           # users[line.split()[1]] += 1\n",
    "            user = line.split()[1]\n",
    "            exercise_parameters = line[2:].split()\n",
    "            \n",
    "            # session at 4 and format at 5\n",
    "            sessions.add(exercise_parameters[4])\n",
    "            formats.add(exercise_parameters[5])\n",
    "            exercise_type = exercise_parameters[4] + exercise_parameters[5]\n",
    "            sentence = ''  # use to see different exercise sentences\n",
    "            duolingo_exercises = exercise_type + ' sentence: '\n",
    "        else:\n",
    "            users[user] += 1\n",
    "            line = line.split()\n",
    "            sentence = sentence + ' ' + line[1]\n",
    "            if len(line[1]) > max_word_len: max_word_len = len(line[1])\n",
    "            word_counts[line[1]] += 1\n",
    "            morph_features = line[3].split('|')\n",
    "            reduced_instance = (exercise_type + ', ' + ', '.join(line[2:len(line) - 4])\n",
    "                                + ', ' + ', '.join(morph_features))\n",
    "            reduced_instances.add(reduced_instance)\n",
    "            instances.add(exercise_type + ', ' + ', '.join(line[1:len(line) - 1]))\n",
    "            # instances.add(line[1])\n",
    "            num_instances += 1\n",
    "\n",
    "# print(sentences)\n",
    "print('sentences:', len(sentences))\n",
    "print('number of exercises: ', num_exercises)\n",
    "print('instances:', len(instances))\n",
    "print('total instances:', num_instances)\n",
    "print('words:', len(word_counts.keys()))\n",
    "print('max word count', np.max(list(word_counts.values())))\n",
    "print('reduced instances:', len(reduced_instances))\n",
    "# print(reduced_instances)\n",
    "print('n users', len(users))\n",
    "print('max n exercises by user', max(users.values()))\n",
    "print('min n exercises by user', min(users.values()))\n",
    "print('formats:', len(formats))\n",
    "print('sessions:', len(sessions))\n",
    "print(formats)\n",
    "print(sessions)\n",
    "with open('fr_en.slam.20171218.dev', 'rt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "\n",
    "        # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "        if len(line) == 0:\n",
    "            sentences.add(sentence)\n",
    "            num_exercises += 1\n",
    "            if num_exercises % 100000 == 0:\n",
    "                print('Loaded ' + str(num_instances) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "\n",
    "        # If the line starts with #, then we're beginning a new exercise\n",
    "        elif line[0] == '#':\n",
    "            list_of_exercise_parameters = line[2:].split()\n",
    "            test_users[line.split()[1]] += 1\n",
    "            exercise_type = list_of_exercise_parameters[4] + list_of_exercise_parameters[5]\n",
    "            sentence = ''  # use to see different exercise sentences\n",
    "            duolingo_exercises = exercise_type + ' sentence: '\n",
    "        else:\n",
    "            line = line.split()\n",
    "            sentence = sentence + ' ' + line[1]\n",
    "            word_counts[line[1]] += 1\n",
    "            if len(line[1]) > max_word_len: max_word_len = len(line[1])\n",
    "            morph_features = line[3].split('|')\n",
    "            reduced_instance = (exercise_type + ', ' + ', '.join(line[2:len(line) - 4])\n",
    "                                + ', ' + ', '.join(morph_features))\n",
    "            reduced_instances.add(reduced_instance)\n",
    "            instances.add(exercise_type + ', ' + ', '.join(line[1:len(line) - 1]))\n",
    "            # instances.add(line[1])\n",
    "            num_instances += 1\n",
    "\n",
    "print('\\n\\nWith test set:')\n",
    "print('sentences:', len(sentences))\n",
    "print('number of exercises: ', num_exercises)\n",
    "print('instances:', len(instances))\n",
    "print('total instances:', num_instances)\n",
    "print('words:', len(word_counts.keys()))\n",
    "print('max word count', np.max(list(word_counts.values())))\n",
    "print('max word length', max_word_len)\n",
    "print('reduced instances:', len(reduced_instances))\n",
    "# print(reduced_instances)\n",
    "\n",
    "print('n test users', len(test_users))\n",
    "print('max n exercises by test user', max(test_users.values()))\n",
    "print('min n exercises by test user', min(test_users.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
