{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatting training exercises...\n",
      "Loaded 285973 instances across 100000 exercises...\n",
      "Loaded 567856 instances across 200000 exercises...\n",
      "Loaded 850511 instances across 300000 exercises...\n",
      "formatting done\n",
      "number of exercises:  326792\n",
      "total instances: 926657\n",
      "n users 1213\n",
      "max n exercises by user 7676\n",
      "distinct reduced exercises: 2131\n",
      "train data users: 1720\n",
      "writing formatted training data...\n",
      "data written to formatted_data_train_.csv\n",
      "formatting test data...\n",
      "test data formatted\n",
      "test data users: 1205\n",
      "writing test data...\n",
      "test data written to formatted_data_test_.csv\n",
      "['format:reverse_translateDET,Definite=Def|Gender=Masc|Number=Sing|fPOS=DET++', 'format:reverse_translateNOUN,Gender=Masc|Number=Sing|fPOS=NOUN++DET', 'format:reverse_translatePRON,Number=Sing|Person=1|PronType=Prs|fPOS=PRON++', 'format:reverse_translateVERB,Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|fPOS=VERB++PRON', 'format:reverse_translateDET,Definite=Ind|Gender=Fem|Number=Sing|PronType=Dem|fPOS=DET++VERB']\n",
      "distinct reduced exercises: 2252\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "saves exercises in format (num_exercises \\n exercises \\n labels \\n, num_exercises \\n exercises \\n labels \\n, ...) \n",
    "where a tuple of three rows are the exercises of one user \n",
    "\"\"\"\n",
    "# total users in file: 1213\n",
    "max_users = 2000\n",
    "max_exercises = 800\n",
    "min_exercises = 0\n",
    "train_file = 'fr_en.slam.20171218.train'\n",
    "test_data_file = 'fr_en.slam.20171218.dev'\n",
    "test_labels_file = 'fr_en.slam.20171218.dev.key'\n",
    "\n",
    "train_formatted_file = 'formatted_data_train_.csv'\n",
    "test_formatted_file = 'formatted_data_test_.csv'\n",
    "\n",
    "exercise_map = {}\n",
    "exercise_i = 0\n",
    "num_train_exercises, num_train_instances, num_test_exercises, num_test_instances = 0, 0, 0, 0\n",
    "# reduced exercises for one-hotting\n",
    "train_exercise_tuples, test_exercise_tuples = [], []\n",
    "train_exercise_tuple, test_exercise_tuple = [0, [], []], [0, [], []]\n",
    "train_label, train_exercise, test_label, test_exercise = '-1', '', '-1', ''\n",
    "users = defaultdict(int)\n",
    "included_users = set()\n",
    "exercise_type = ''\n",
    "cur_user = ''\n",
    "prev_user = ''\n",
    "prev_pos = ''\n",
    "word_counts = defaultdict(int)\n",
    "print('formatting training exercises...')\n",
    "\n",
    "def word_len(word):\n",
    "    n = len(word)\n",
    "    if n < 4: return 'short'\n",
    "    if n < 7: return 'medium'\n",
    "    if n < 10: return 'med_long'\n",
    "    else: return 'long'\n",
    "\n",
    "    # Compute word counts\n",
    "with open(train_file, 'rt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        # If the line starts with #, then we're beginning a new exercise\n",
    "        elif line[0] == '#':\n",
    "            continue\n",
    "        else:\n",
    "            line = line.split()\n",
    "            word_counts[line[1]] += 1\n",
    "\n",
    "max_word_count = np.max(list(word_counts.values()))\n",
    "freqs = defaultdict(int)\n",
    "def word_freq(token):\n",
    "    frequency = word_counts[token.lower()] / max_word_count\n",
    "    if frequency < .001: freqs['<.001'] += 1; return 'very_rare'\n",
    "    if frequency < .005: freqs['<.005'] += 1; return 'rare'\n",
    "    if frequency < .01: freqs['<.01'] += 1; return 'medium_rare'\n",
    "    if frequency < .05: freqs['<.05'] += 1; return 'semi_rare'\n",
    "    if frequency < .1: freqs['<.1'] += 1;return 'quite_common'\n",
    "    if frequency < .5: freqs['<.5'] += 1; return 'common'\n",
    "    else: freqs['>=.5'] += 1; return 'very_common'\n",
    "\n",
    "\n",
    "with open(train_file, 'rt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "        n_ex = train_exercise_tuple[0]\n",
    "        if len(line) == 0:\n",
    "            if n_ex > max_exercises or (cur_user != prev_user and n_ex > 0):\n",
    "                if n_ex > min_exercises: \n",
    "                    train_exercise_tuples.append(deepcopy(train_exercise_tuple))\n",
    "                    included_users.add(prev_user)\n",
    "                train_exercise_tuple = [0, [], []]\n",
    "            num_train_exercises += 1\n",
    "            prev_user = cur_user\n",
    "            if num_train_exercises % 100000 == 0:\n",
    "                print('Loaded ' + str(num_train_instances) + ' instances across ' + str(num_train_exercises) + ' exercises...')\n",
    "\n",
    "        # If the line starts with #, then we're beginning a new exercise\n",
    "        elif line[0] == '#':\n",
    "            cur_user = line.split()[1]\n",
    "            if num_train_exercises == 0: prev_user = cur_user\n",
    "            exercise_parameters = line[2:].split()\n",
    "            # session is at index 4 and format at index 5\n",
    "            #exercise_type = exercise_parameters[4] + ', ' + exercise_parameters[5]\n",
    "            exercise_type = exercise_parameters[5]\n",
    "            prev_pos = ''\n",
    "        else:\n",
    "            users[cur_user] += 1\n",
    "            line = line.split()\n",
    "            train_label = int(line[-1])\n",
    "            #train_exercise = exercise_type + ','.join(line[2:3])\n",
    "            #train_exercise = exercise_type + line[1] + prev_pos \n",
    "            train_exercise = exercise_type + ','.join(line[2:4]) + prev_pos \n",
    "            #train_exercise = exercise_type + ','.join(line[2:4]) + prev_pos + word_freq(line[1]) + word_len(line[1])\n",
    "            #train_exercise = exercise_type + ','.join(line[2:4]) + word_freq(line[1]) + word_len(line[1])\n",
    "            prev_pos = line[2]\n",
    "            if train_exercise not in exercise_map:\n",
    "                exercise_map[train_exercise] = exercise_i\n",
    "                exercise_i += 1\n",
    "            train_exercise_tuple[0] += 1\n",
    "            train_exercise_tuple[1].append(str(exercise_map[train_exercise]))\n",
    "            train_exercise_tuple[2].append(str(train_label))\n",
    "            num_train_instances += 1\n",
    "\n",
    "print('formatting done')\n",
    "print('number of exercises: ', num_train_exercises)\n",
    "print('total instances:', num_train_instances)\n",
    "print('n users', len(users))\n",
    "print('max n exercises by user', max(users.values()))\n",
    "print('distinct reduced exercises:', len(exercise_map))\n",
    "print('train data users:', len(train_exercise_tuples))\n",
    "\n",
    "print('writing formatted training data...')\n",
    "try: os.remove(train_formatted_file)\n",
    "except OSError: pass\n",
    "f = open(train_formatted_file, 'w')\n",
    "for tup in train_exercise_tuples[:max_users]:\n",
    "    f.write(str(tup[0]) + '\\n')\n",
    "    f.write(','.join(tup[1]) + '\\n')\n",
    "    f.write(','.join(tup[2]) + '\\n')\n",
    "print('data written to', train_formatted_file)\n",
    "\n",
    "print('formatting test data...')\n",
    "with open(test_data_file) as f1, open(test_labels_file) as f2:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "        if len(line) == 0:\n",
    "            if prev_user != cur_user:\n",
    "                test_exercise_tuples.append(deepcopy(test_exercise_tuple))\n",
    "                test_exercise_tuple = [0, [], []]    \n",
    "            num_test_exercises += 1\n",
    "            prev_user = cur_user\n",
    "            if num_test_exercises % 100000 == 0:\n",
    "                print('Loaded ' + str(num_test_instances) + ' instances across '\n",
    "                      + str(num_test_exercises) + ' exercises...')\n",
    "\n",
    "        # If the line starts with #, then we're beginning a new exercise\n",
    "        elif line[0] == '#':\n",
    "            cur_user = line.split()[1]\n",
    "            if num_test_exercises == 0: prev_user = cur_user\n",
    "            exercise_parameters = line[2:].split()\n",
    "            # session is at index 4 and format at index 5\n",
    "            #exercise_type = exercise_parameters[4] + ', ' + exercise_parameters[5]\n",
    "            exercise_type = exercise_parameters[5]\n",
    "            prev_pos=''\n",
    "        else:\n",
    "            users[cur_user] += 1\n",
    "            line = line.split()\n",
    "            test_instance_label = f2.readline().split()\n",
    "            assert line[0] == test_instance_label[0]\n",
    "            test_label = test_instance_label[1]\n",
    "            test_exercise = exercise_type + ','.join(line[2:4]) + prev_pos # morph features\n",
    "            #test_exercise = exercise_type + line[1] + prev_pos # word tokens\n",
    "            #test_exercise = exercise_type + ','.join(line[2:4]) + prev_pos + word_freq(line[1]) + word_len(line[1])\n",
    "            #test_exercise = exercise_type + ','.join(line[2:4]) + word_freq(line[1]) + word_len(line[1])\n",
    "            prev_pos = line[2]\n",
    "            if test_exercise not in exercise_map:\n",
    "                exercise_map[test_exercise] = exercise_i\n",
    "                exercise_i += 1\n",
    "                #continue\n",
    "            test_exercise_tuple[0] += 1\n",
    "            test_exercise_tuple[1].append(str(exercise_map[test_exercise]))\n",
    "            test_exercise_tuple[2].append(test_label)\n",
    "            num_test_instances += 1\n",
    "\n",
    "print('test data formatted')\n",
    "print('test data users:', len(test_exercise_tuples))\n",
    "print('writing test data...')\n",
    "try: os.remove(test_formatted_file)\n",
    "except OSError: pass\n",
    "f = open(test_formatted_file, 'w')\n",
    "for tup in test_exercise_tuples[:max_users]:\n",
    "    f.write(str(tup[0]) + '\\n')\n",
    "    f.write(','.join(tup[1]) + '\\n')\n",
    "    f.write(','.join(tup[2]) + '\\n')\n",
    "print('test data written to', test_formatted_file)\n",
    "print(list(exercise_map.keys())[:5])\n",
    "print('distinct reduced exercises:', len(exercise_map))\n",
    "#print(word_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
